%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
% forked from here everything after 1.15 version of cross.ltx
% this is the original bits.

%\documentclass{article}      % Specifies the document class

%\usepackage{amsmath}

%
% The real thing:
%

\chapter{Early cross product generalization and motivation attempt}
\label{chap:crossOld}
%\author{Peeter Joot}         % Declares the author's name.
\date{ May 2000.  crossOld.tex }

%\begin{document}             % End of preamble and beginning of text.

%\maketitle{}

\section{Introduction/Abstract}

The cross product is an ugly arbitrary seeming sort of beast, but it is a beast that
describes many sorts of physical and mathematical situations.  In vector calculus
cross product terms and it relative the determinant end up occurring all over the place,
and in physics the cross product also occurs in many contexts.
Examples are Stokes theorem, Jacobian transformations, normal equations, the
curl operator, Maxwell's equations, torque, and the list goes on.
In many of
these cases the mathematics has no logical tie to three dimensions, yet
the cross product is an explicitly three dimensional sort of beast.
The cross product and the dot product have some similarities in form
yet the cross product is only defined for \R{3}, while the dot product
can be defined for \R{n} including \(n < 3\), and even extended easily to \C{n}.
The open question remains of how to generalize it and the math that
is related to it to higher dimensions and other mathematical fields.

\section{The cross product in physical situations}

On of the common places where the cross product appears naturally is in the
definition of torque.
The basic definition of torque as a scalar quantity is the product of the radial distance times
the perpendicular force.  The formula in terms of components in three dimensions given a force vector
\(\BF = (F_x, F_y, F_z)\) and the
radial distance \(\Br = (x, y, z)\) is pretty messy, which is the reason it
is typically described by means of a cross product, and
a generalized torque ``vector'' with a magnitude and direction.

%My Feynman book gives a derivation of for the formula for torque in one dimension as
%the differential work per unit rotation.  This derivation is interesting
%because it yields in a simple fashion a torque formula without having to
%introduce the complexities of the cross product or the torque pseudo-vector.  I will
%not reproduce it here, but will go through a generalized derivation for the torque
%equation when the plane of rotation has an arbitrary orientation in space, rather
%than being restricted to the x,y plane (or y,z or z,x).

The torque expression can be seen to be a natural result of the examination
of the differential work per unit rotation.
\footnote{The Feynman lectures, where a one dimension derivation
of torque is given in this fashion for the (x,y) plane.}
A derivation of this torque expression for an arbitrary rotation
in space will be given in the following sections, first in two dimensions then in three.
The expression for angular velocity for a rotational motion will also be derived.  In each of
these physical scenarios it will be seen that the expression for the cross product arises.
These physical preliminaries will
lead to a technique for which a possible higher dimensional cross product can
be formed and also show how a cross product operator can be defined in a convenient
and natural matrix formulation.

%To start things off, some basic vector algebra results will be presented.

\subsection{torque in two dimensions}

%Feynman's derivation of torque in two dimensions was geometrical and also was quite simple.
In
modern physics where torque is a vector in three dimensions
%even if the rotation is constrained to two dimensions
it does not make sense to talk of a two dimensional torque, but
%There is no reason
the magnitude of the torque for a rotation confined to a plane can be defined without
reference to the plane's normal (ie: the third dimension).
%in two dimensions can not be determined even if the
%the third dimension or rotational axis has not been defined.
This
%, strictly speaking,
is what is meant by torque
in this section.
Application of transformations to and from a rotated frame will be used to define an expression for torque in
\R{2}.  This approach can be applied to do the same in \R{3}, yielding a natural occurrence of the mathematical
form known as the cross product.  The cross product is typically first introduced from its projective
definition, but this form does not easily lead to generalizations in higher dimensions.  Using this procedure
the cross product will be shown to be an expression of incremental rotation, and an \R{n} cross product will
be defined by examination of what we will call an \R{n} rotation.

%arrive at the same result, but have the additional benefit of indicating an approach for the same
%problem for \R{3} and paves the way for generalizing the cross product for \R{n}.

If a rotation inducing force \(\BF\) is applied to an object in space with position \(\Br\) then the only component of the
force that will do work is the component perpendicular to the direction \(\Br\).  Let a new coordinate system
with unit vectors \(\{\rcap = \Br/\norm{\Br}\), \(\thetacap\}\) be defined where \(\thetacap\) is the unit vector perpendicular to \(\Br\) in the direction of positive angular increase.  In this coordinate system
for the force \(\BF' = (F_r, F_\theta)\), only the \(F_\theta\)
component does any work.

To transform to the \(r,\theta\) basis, it can be noted that \(\thetacap \propto (-y, x)\).  Thus
\(\rcap = \inv{r}(x,y)\), \(\thetacap = \inv{r}(-y,x)\), and
\footnote{see appendix for a refresh on change of basis calculations and for the \(\BM\) notation used here}
$\BM =
\inv{r}
\Bigl[
\begin{smallmatrix}
 x & y \\
-y & x
\end{smallmatrix}
\Bigr]
$

The work done \(dW\) is
\begin{equation}\label{eqn:crossOld:20}
\begin{aligned}
dW &=\dotprod{\BF}{d\Bl} \\
   &=\dotprod{\BF'} r d\thetacap \\
   &= F_\theta r d\theta
\end{aligned}
\end{equation}

and
\begin{equation}\label{eqn:crossOld:40}
\begin{aligned}
\BF' &= \BM \BF \\
     &=
\inv{r}
\begin{bmatrix}
 x & y \\
-y & x
\end{bmatrix}
\begin{bmatrix}
 F_x \\
 F_y
\end{bmatrix} \\
     &=
\inv{r}
\begin{bmatrix}
 x Fx - y F_y \\
-y Fx + x F_y
\end{bmatrix}
\end{aligned}
\end{equation}

so
\begin{equation*}
dW = (x F_y - y F_x) d\theta
\end{equation*}

What is being called the torque
\(\tau\)
is this scalar quantity
\(\tau = \D{\theta}{W} = x F_y - y F_x\),
the work per unit rotation for a force \(\BF = (F_x, F_y)\)
applied at a point \(\Br = (x, y)\) from the origin about which the rotation occurs.

It is also easily noted that the transformation
\begin{equation*}
\BM =
\inv{r}
\begin{bmatrix}
 x & y \\
-y & x
\end{bmatrix}
=
\begin{bmatrix}
 x/r & y/r \\
-y/r & x/r
\end{bmatrix}
=
\begin{bmatrix}
 \cos\theta & \sin\theta \\
-\sin\theta & \cos\theta
\end{bmatrix}
=-\BR_\theta
={\BR_\theta}^T
={\BR_\theta}^{-1}
\end{equation*}

Where
\(\BR_\theta\) is the transformation matrix for a rotation through an angle \(\theta\).

The torque can also be calculated in an alternate fashion by using the
rotation matrix.
For a rotation
through a small angle \(d\theta\) this transformation becomes,

\begin{equation*}
\BR_{d\theta} =
\begin{bmatrix}
 \cos{d\theta} & -\sin{d\theta} \\
 \sin{d\theta} & \cos{d\theta}
\end{bmatrix}
=
\begin{bmatrix}
 1 & -d\theta \\
 d\theta & 1
\end{bmatrix}
\end{equation*}

and so the displaced vector is
\begin{equation*}
\Br' = \BR_{d\theta} \Br =
\Bigr( \BI +
\begin{bmatrix}
 0 & -d\theta \\
 d\theta & 0
\end{bmatrix}
\Bigl) \Br
\end{equation*}

which gives the differential change in position
\begin{equation*}
d\Br = \Br' - \Br =
(\BR_{d\theta}-\BI) \Br
=
\begin{bmatrix}
 0 & -d\theta \\
 d\theta & 0
\end{bmatrix}
\Br
=
\begin{bmatrix}
 0 & -1 \\
 1 & 0
\end{bmatrix}
\Br d\theta
\end{equation*}

and the work done is

\begin{equation}\label{eqn:crossOld:60}
\begin{aligned}
dW &=\dotprod{\BF}{d\Br} \\
   &=
\begin{bmatrix}
F_x & F_y
\end{bmatrix}
\begin{bmatrix}
 0 & -1 \\
 1 & 0
\end{bmatrix}
\Br d\theta \\
   &=
\begin{bmatrix}
F_y & -F_x
\end{bmatrix}
\begin{bmatrix}
x \\
y
\end{bmatrix}
d\theta \\
   &=
(x F_y - y F_x) d\theta
\end{aligned}
\end{equation}

This same technique can be applied in three and more dimensions, which will be done in
the following sections.

\subsection{torque in three dimensions}
For three dimensions successive rotations in the \(xy, yz\) and \(zx\) planes can be applied

\begin{equation}\label{eqn:crossOld:80}
\begin{aligned}
\BR_{d\theta_{xy}}
&=
\BR_{d\theta_z}
&=
\begin{bmatrix}
1 & -d\theta_z & 0 \\
 d\theta_z & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} \\
\BR_{d\theta_{yz}}
&=
\BR_{d\theta_x}
&=
\begin{bmatrix}
 1 & 0 & 0 \\
 0 & 1 & -d\theta_x \\
 0 & d\theta_x & 1
\end{bmatrix} \\
\BR_{d\theta_{zx}}
&=
\BR_{d\theta_y}
&=
\begin{bmatrix}
 1 & 0 & d\theta_y \\
 0 & 1 & 0 \\
 -d\theta_y & 0 & 1
\end{bmatrix} \\
\end{aligned}
\end{equation}

Applying these transformations in sequence is a bit messy, but certainly easier than
applying three successive large rotations in sequence.  The mess of sine and cosine terms
for that is horrendous if you care to try!

The calculation for the sequential application of
\(\BR_{d\theta_{xy}}\)
,
\(\BR_{d\theta_{yz}}\)
and
\(\BR_{d\theta_{zx}}\)
is below.

\begin{multline*}
\BR_{d\theta_{zx}}
\BR_{d\theta_{yz}}
\BR_{d\theta_{xy}}
%
=
%
\BR_{d\theta_y}
\BR_{d\theta_x}
\BR_{d\theta_z} \\
%
=
%
% \BR_\theta_y
\begin{bmatrix}
 1 & 0 & d\theta_y \\
 0 & 1 & 0 \\
 -d\theta_y & 0 & 1
\end{bmatrix}
% \BR_{d\theta_x}
\begin{bmatrix}
 1 & 0 & 0 \\
 0 & 1 & -d\theta_x \\
 0 & d\theta_x & 1
\end{bmatrix}
% \BR_{d\theta_z}
\begin{bmatrix}
1 & -d\theta_z & 0 \\
d\theta_z & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} \\
%
=
%
\begin{bmatrix}
1 & d\theta_x\,d\theta_y & d\theta_y \\
0 & 1 & -d\theta_x \\
-d\theta_y & 0 & 1
\end{bmatrix}
% \BR_{d\theta_z}
\begin{bmatrix}
1 & -d\theta_z & 0 \\
d\theta_z & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} \\
%
=
%
\begin{bmatrix}
1+d\theta_x\,d\theta_y\,d\theta_z & -d\theta_z + d\theta_x\,d\theta_y & d\theta_y \\
d\theta_z & 1 & -d\theta_x \\
-d\theta_y + d\theta_x\,d\theta_z & d\theta_y\,d\theta_z d\theta_x & 1
\end{bmatrix} \\
%
=
%
\BI
+
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix}
+
\begin{bmatrix}
0 & d\theta_x\,d\theta_y & 0 \\
0 & 0 & 0 \\
d\theta_x\,d\theta_z & d\theta_y\,d\theta_z & 0
\end{bmatrix} \\
+
\begin{bmatrix}
d\theta_x\,d\theta_y\,d\theta_z & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix} \\
\end{multline*}

Note that if the second and third order terms are neglected then
\begin{equation*}
\BR_{d\theta_{zx}}
\BR_{d\theta_{yz}}
\BR_{d\theta_{xy}} - \BI
%
=
%
\BR_{d\theta_y}
\BR_{d\theta_x}
\BR_{d\theta_z} - \BI
%
\approx
%
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix}
\end{equation*}

and that

\begin{multline*}
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix}
= \\
% \BR_\theta_y
\begin{bmatrix}
 0 & 0 & d\theta_y \\
 0 & 0 & 0 \\
-d\theta_y & 0 & 0
\end{bmatrix}
+
% \BR_{d\theta_x}
\begin{bmatrix}
 0 & 0 & 0 \\
 0 & 0 & -d\theta_x \\
 0 & d\theta_x & 0
\end{bmatrix}
% \BR_{d\theta_z}
+
\begin{bmatrix}
0 & -d\theta_z & 0 \\
d\theta_z & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\end{multline*}

The following result

\begin{multline*}
\BR_{d\theta_{zx}}
\BR_{d\theta_{yz}}
\BR_{d\theta_{xy}}
%
=
%
\BR_{d\theta_y}
\BR_{d\theta_x}
\BR_{d\theta_z} \\
\approx
\BI +
(\BR_{d\theta_y} - \BI)
+
(\BR_{d\theta_x} - \BI)
+
(\BR_{d\theta_z} - \BI)
=
\BR_{d\theta_{xyz}}
\end{multline*}
is independent of the order of application of the rotations, which is not true for the case
when the rotations are not infinitesimal.

Using this a differential change in \(\Br\) due to the rotation is

\begin{equation}\label{eqn:crossOld:100}
\begin{aligned}
d\Br = \Br' - \Br =
(\BR_{d\theta_{xyx}}-\BI) \Br
&=
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix} \Br \\
&=
-
\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix}
\begin{bmatrix}
d\theta_x \\
d\theta_y \\
d\theta_z
\end{bmatrix}
\end{aligned}
\end{equation}

This vector of \(d\theta_i\) components can be written
\begin{equation*}
d\Btheta =
\begin{bmatrix}
d\theta_x \\
d\theta_y \\
d\theta_z
\end{bmatrix}
\end{equation*}

In the same fashion as in the two dimensional case above,
this can be applied
to
calculate the work done,

\begin{equation}\label{eqn:crossOld:120}
\begin{aligned}
dW &=\dotprod{\BF}{d\Br} \\
   &=
\begin{bmatrix}
F_x & F_y & F_z
\end{bmatrix}
\Biggl(
   -
\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix} d\Btheta
\Biggr)
\\
 &=
-
{\Biggl(
{\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix}}^T
\begin{bmatrix}
F_x \\
F_y \\
F_z
\end{bmatrix}
\Biggr)}^T
d\Btheta
\\
 &=
 \Biggl(
\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix}
\BF
\Biggr) \cdot d\Btheta
\end{aligned}
\end{equation}

So in the three dimensional case we can write
\begin{equation*}
dW =\dotprod{\BF}{d\Br} =\dotprod{\Btau}{d\Btheta}
\end{equation*}

Where in analogy with the two dimensional case
\(dW =\dotprod{\BF}{d\Br} = \tau d\theta\) we can define the torque as this
quantity \(\Btau\),

\begin{equation*}
\Btau =
\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix}
\BF
=
\begin{bmatrix}
y F_z - z F_y \\
z F_x - x F_z \\
x F_y - y F_x
\end{bmatrix}
=
\crossprod{\Br}{\BF}
\end{equation*}

the work per unit ``angle'' of rotation in space.

\subsection{angular velocity in three dimensions}

One of the formulas that I recall was always just presented and never derived (for the three dimensional case)
was that for
\(\D{t}{\Br}\) in terms of a vector angular velocity.  This is another equation that the cross product
comes up, and an equation whose derivation is easily done given some of the work above.

Let \(\Bomega = \D{t}{}\Bigl(\theta_x, \theta_y, \theta_z\Bigr)\) then in the limit

\begin{equation}\label{eqn:crossOld:140}
\begin{aligned}
\D{t}{\Br} &= \frac{\Br(t + dt) - \Br(t)}{dt} \\
%           &= \frac{\Br' - \Br}{dt} \\
           &= \frac{\BR_{d\theta_{xyx}}\Br -\Br}{dt} \\
           &= \frac{(\BR_{d\theta_{xyx}}-\BI) \Br}{dt} \\
	   &= \inv{dt}
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix} \Br \\
           &=
\begin{bmatrix}
\omega_y z -\omega_z y \\
\omega_z x -\omega_x z \\
\omega_x y -\omega_y x
\end{bmatrix}
\end{aligned}
\end{equation}

Thus
\begin{equation*}
\Bv = \crossprod{\Bomega}{\Br}
\end{equation*}

Note that these were not derivations of the cross product, but just
physical situations in which the cross product occurs.

\section{generalizing the cross product}

\subsection{defining a cross product operator}

In each of the physical situations where the cross product occurs
above (ie: torque and angular velocity) the derivation of
these formulas was closely tied to the
differential change in position \(d\Br\) after application of a rotation
transformation \(\BR_{d\theta_{xyz}}\),
%limiting expression for
%a three dimensional differential rotation
%\(\BR_{d\theta_{xyz}}\)
%applied to a vector \(\Br\)

\begin{equation*}
d\Br =
(\BR_{d\theta_{xyz}} - \BI) \Br =
\begin{bmatrix}
0 & -d\theta_z & d\theta_y \\
d\theta_z & 0 & -d\theta_x \\
-d\theta_y & d\theta_x & 0
\end{bmatrix} \Br
=
%-
\begin{bmatrix}
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{bmatrix} d\Btheta
\end{equation*}

As a side effect of the derivations above the cross
product shows up
tied
to a
matrix form since the rotation transformation was defined in matrix form.
Expressing the cross product in this matrix form has a certain aesthetic pleasantness
that the
component form lacks.  It can also be seen that
as an operational quantity
the matrices above,
whether they contain the \(d\theta_i\) or the \(r_i\) terms,
are the important part of the equation, and we can drop the vector multiplication
part of the expression.

A cross product operator \(\Bu \cross\) can be defined for and vector \(\Bu\)
in \R{3},

\begin{equation*}
\crossop{\Bu}=
\begin{bmatrix}
0 & -u_z & u_y \\
u_z & 0 & -u_x \\
-u_y & u_x & 0
\end{bmatrix}
\end{equation*}

When applied to a vector \(\Bv\)
\begin{equation*}
(\Bu \cross) \Bv =
\begin{bmatrix}
0 & -u_z & u_y \\
u_z & 0 & -u_x \\
-u_y & u_x & 0
\end{bmatrix}
\begin{bmatrix}
v_x \\
v_y \\
v_z
\end{bmatrix}
= \crossprod{\Bu}{\Bv}
\end{equation*}

which is what we typically define as \(\cross{\Bu}{\Bv}\).  Using this new notation the change
in position can be written,

\begin{equation*}
d\Br
=  (\crossprod{d\Btheta}{})\Br
= -(\crossprod{\Br}{})d\Btheta
\end{equation*}

By defining the cross product in this fashion, the rotational and physical origins have been discarded,
%As an operational entity there is no reason to refer
%to the differential rotation vector \(d\Btheta = (d\theta_x, d\theta_y, d\theta_z)\) anymore,
but it is interesting to note the way that the cross product
and a rotation in space are related in a fundamental way.

\subsection{decomposition of the cross product operator}

The cross product operator as defined above can be antisymetrically
decomposed into its positive and negative portions as follows
\begin{equation*}
\crossop{\Bu}=
\begin{bmatrix}
0 & -u_z & u_y \\
u_z & 0 & -u_x \\
-u_y & u_x & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & u_y \\
u_z & 0 & 0 \\
0 & u_x & 0
\end{bmatrix}
-
\begin{bmatrix}
0 & 0 & u_y \\
u_z & 0 & 0 \\
0 & u_x & 0
\end{bmatrix}^T
\end{equation*}

Each half of the right hand side can be diagonalized, but not via a change of basis
\footnote
{
I was playing around with this at one point
and I believe it was possible to diagonalized the
matrix, but not in a simple fashion, as it required complex eigenvalues and
eigenvectors, and the solution of a cubic equation.
}
, as follows:
\begin{multline*}
\crossop{\Bu}=
\begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
u_x & 0 & 0 \\
0 & u_y & 0 \\
0 & 0 & u_z
\end{bmatrix}
\begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix} \\
-
\begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}
\begin{bmatrix}
u_x & 0 & 0 \\
0 & u_y & 0 \\
0 & 0 & u_z
\end{bmatrix}
\begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}
\end{multline*}

The matrix
\( \BP =
\Bigl[
\begin{smallmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{smallmatrix}
\Bigr]
\) above is an interesting one, as \(\BP^{-1} = \BP^T = \BP^2\).

%From this it can be seen that one can write
%
%\begin{multline*}
%\begin{bmatrix}
%0 & 0 & 1 \\
%1 & 0 & 0 \\
%0 & 1 & 0
%\end{bmatrix}
%\begin{bmatrix}
%u_x & 0 & 0 \\
%0 & u_y & 0 \\
%0 & 0 & u_z
%%\end{bmatrix}
%\begin{bmatrix}
%0 & 0 & 1 \\
%1 & 0 & 0 \\
%0 & 1 & 0
%\end{bmatrix} \\
%=
%\begin{bmatrix}
%0 & 1 & 0 \\
%0 & 0 & 1 \\
%1 & 0 & 0
%\end{bmatrix}
%\Biggl(
%\begin{bmatrix}
%0 & 1 & 0 \\
%0 & 0 & 1 \\
%1 & 0 & 0
%\end{bmatrix}
%\begin{bmatrix}
%u_x & 0 & 0 \\
%0 & u_y & 0 \\
%0 & 0 & u_z
%\end{bmatrix}
%\begin{bmatrix}
%0 & 0 & 1 \\
%1 & 0 & 0 \\
%0 & 1 & 0
%\end{bmatrix}
%\Biggr) \\
%=
%\Biggl(
%\begin{bmatrix}
%0 & 0 & 1 \\
%1 & 0 & 0 \\
%%0 & 1 & 0
%\end{bmatrix}
%\begin{bmatrix}
%u_x & 0 & 0 \\
%0 & u_y & 0 \\
%0 & 0 & u_z
%\end{bmatrix}
%\begin{bmatrix}
%0 & 1 & 0 \\
%0 & 0 & 1 \\
%1 & 0 & 0
%\end{bmatrix}
%\Biggr)
%\begin{bmatrix}
%0 & 1 & 0 \\
%0 & 0 & 1 \\
%1 & 0 & 0
%\end{bmatrix}
%\end{multline*}
%
%where the terms inside the braces represent a change of basis transformation.

If one defines \(D(\Bu)\) as the matrix with the terms of \(\Bu\) are along the diagonal, then
there is now a nice and concise way of writing the cross product operator.

\begin{equation*}
\crossop{\Bu}= \BP D(\Bu) \BP - \BP^T D(\Bu) \BP^T
\end{equation*}

This is also
possibly suggestive of how to define the cross product in greater than three dimensions, for
it could possibly be of the same form where \(\BP\) is a permutation or some other transformation.

%An alternative form is also possible, by taking advantage of the \(\BP\) decomposition noted above.
%Let \(G(\Bu) = \BP^T D(\Bu) \BP = G(\Bu)^T\), then
%\begin{align*}
%\crossop{\Bu}&= \BP^T (\BP^T D(\Bu) \BP) - (\BP^T D(\Bu) \BP) \BP \\
%             &= \BP^T G(\Bu) - G(\Bu)^T \BP
%\end{align*}
%
% -- this does not really buy us anything to mention.
%

\subsection{cross product via four dimensional rotation}

As was noted above the cross product is closely related to a rotation in space.
This leads to a possible means for generalizing the cross product to
higher dimensions by examining the four dimensional rotation operator.

Some clarification here is probably in order.  What is meant by a four
dimensional rotation?  When the three dimensional rotation
operator was defined, it was the product in the limit of applying a possible rotation
\(d\theta_{xy}\) around the \(z\) axis, a possible rotation
\(d\theta_{yz}\) around the \(x\) axis, and a possible rotation
\(d\theta_{zx}\) around the \(y\) axis.  It is important to note that the
magnitude of these rotations is small, because otherwise the result
is different according to which order each of the rotations is applied.
\footnote{
I am not even sure that this composite rotation is a
single rotation in the traditional sense of a rotation along a plane in
space.
}
A four dimension differential rotation
operator can be defined in the same fashion as the limit of the products of the rotations
in each plane.  This is slightly more complicated in four dimensions than
in three since a rotation can be
simultaneously
perpendicular to two different axis, rather than one.  For example,
a rotation in the \(xy\) plane is perpendicular to both the \(z\) axis and the
\(w\) axis, if the space is defined as having \(w\), \(x\), \(y\), and \(z\)
components.

Each of the possible differential rotations will be enumerated below.  Let
\(\Bu = (d\theta_w, d\theta_x, d\theta_y, d\theta_z)\)
where each of the \(d\theta_i\) terms is a rotation perpendicular to the \(i\)
axis.

Differential rotations in the \(1, 2, 3\) subspace,
in the \(1, 2\) plane perpendicular to \(3\),
in the \(2, 3\) plane perpendicular to \(1\),
in the \(3, 1\) plane perpendicular to \(2\), respectively.
\begin{equation*}
\begin{bmatrix}
 1   &-u_3  & 0    & 0   \\
 u_3 & 1    & 0    & 0   \\
 0   & 0    & 1    & 0   \\
 0   & 0    & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
   1 &  0   & 0    & 0    \\
   0 &  1   &-u_1  & 0    \\
   0 &  u_1 & 1    & 0    \\
   0 &  0   & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
 1   & 0    &  u_2 & 0    \\
 0   & 1    & 0    & 0    \\
-u_2 & 0    & 1    & 0    \\
   0 &  0   & 0    & 1
\end{bmatrix}
\end{equation*}

Differential rotations in the \(1, 2, 4\) subspace,
in the \(1, 2\) plane perpendicular to \(4\),
in the \(2, 4\) plane perpendicular to \(1\),
in the \(4, 1\) plane perpendicular to \(2\), respectively.
\begin{equation*}
\begin{bmatrix}
 1   &-u_4  & 0    & 0   \\
 u_4 & 1    & 0    & 0   \\
 0   & 0    & 1    & 0   \\
 0   & 0    & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
   1 &  0   & 0    & 0   \\
   0 &  1   & 0    &-u_1 \\
 0   & 0    & 1    & 0   \\
   0 &  u_1 & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
 1   & 0    & 0    & u_2 \\
 0   & 1    & 0    & 0    \\
 0   & 0    & 1    & 0    \\
-u_2 & 0    & 0    & 1
\end{bmatrix}
\end{equation*}

Differential rotations in the \(1, 3, 4\) subspace,
in the \(1, 3\) plane perpendicular to \(4\),
in the \(3, 4\) plane perpendicular to \(1\),
in the \(4, 1\) plane perpendicular to \(3\), respectively.
\begin{equation*}
\begin{bmatrix}
 1   & 0    &-u_4  & 0   \\
 0   & 1    & 0    & 0   \\
 u_4 & 0    & 1    & 0   \\
 0   & 0    & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
   1 & 0    &  0   & 0   \\
 0   & 1    & 0    & 0   \\
   0 & 0    &  1   &-u_1 \\
   0 & 0    &  u_1 & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
 1   & 0    & 0    &  u_3 \\
 0   & 1    & 0    & 0    \\
 0   & 0    & 1    & 0    \\
-u_3 & 0    & 0    & 1
\end{bmatrix}
\end{equation*}

Differential rotations in the \(2, 3, 4\) subspace
in the \(2, 3\) plane perpendicular to \(4\),
in the \(3, 4\) plane perpendicular to \(2\),
in the \(4, 2\) plane perpendicular to \(3\), respectively.
\begin{equation*}
\begin{bmatrix}
   1 & 0    &  0   & 0   \\
   0 & 1    &-u_4  & 0   \\
   0 &  u_4 & 1    & 0   \\
   0 & 0    & 0    & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
   1 & 0 &  0   & 0   \\
   0 & 1 &  0   & 0   \\
   0 & 0 &  1   &-u_2 \\
   0 & 0 &  u_2 & 1
\end{bmatrix}
%\end{equation*}
,
%\begin{equation*}
\begin{bmatrix}
 1   & 0   & 0    & 0   \\
 0   & 1   & 0    & u_3 \\
 0   & 0   & 1    & 0    \\
 0   &-u_3 & 0    & 1
\end{bmatrix}
\end{equation*}

In the limit, where any \(d\theta_i d\theta_j\) or higher order terms are
neglected, the product of all of these matrices \(\BR_i\) is

\begin{multline*}
\BR = \prod_i\BR_i \approx \BI + \sum_i(\BR_i-\BI) = \\
\begin{bmatrix}
%
%=================================
% 0   &-u_3  & 0    & 0   \\
% 0   & 0    &  u_2 & 0    \\
% 0   &-u_4  & 0    & 0   \\
% 0   & 0    & 0    &  u_2 \\
% 0   & 0    &-u_4  & 0   \\
% 0   & 0    & 0    &  u_3 \\
% ---------------------
1 &-u_3-u_4 &u_2-u_4 & u_2+u_3 \\
%=================================
% u_3 & 0    & 0    & 0   \\
%   0 &  0   &-u_1  & 0    \\
% u_4 & 0    & 0    & 0   \\
%   0 &  0   & 0    &-u_1 \\
%   0 & 0    &-u_4  & 0   \\
% 0   & 0   & 0    &  u_3 \\
% ---------------------
 u_3+u_4 & 1 &-u_1-u_4 &-u_1+u_3 \\
%=================================
%   0 &  u_1 & 0    & 0    \\
%-u_2 & 0    & 0    & 0    \\
% u_4 & 0    & 0    & 0   \\
%   0 & 0    &  0   &-u_1 \\
%   0 &  u_4 & 0    & 0   \\
%   0 & 0 &  0   &-u_2 \\
% ---------------------
u_4-u_2 &  u_1+u_4 & 1 &-u_1-u_2 \\
%=================================
%   0 &  u_1 & 0    & 0
%-u_2 & 0    & 0    & 0
%   0 & 0    &  u_1 & 0
%-u_3 & 0    & 0    & 0
%   0 & 0 &  u_2 & 0
% 0   &-u_3 & 0    & 0
% ---------------------
-u_2-u_3 &u_1-u_3 &  u_1+u_2 & 1
\end{bmatrix}
\end{multline*}

From this in the same fashion as was done for three dimensions
a cross product operator can be defined for \(\Bu\) as \(\crossop{\Bu}= \BR - \BI\)
to give a cross product definition for \R{4}

\begin{equation*}
\crossop{\Bu}=
\begin{bmatrix}
           0 & - u_3 - u_4 &   u_2 - u_4 &   u_2 + u_3 \\
   u_3 + u_4 & 0           & - u_1 - u_4 &   u_3 - u_1 \\
 - u_2 + u_4 & u_1 + u_4   & 0           & - u_1 - u_2 \\
 - u_2 - u_3 & u_1 - u_3   & u_1 + u_2   &   0
\end{bmatrix}
\end{equation*}

It has yet to be shown that this ``cross product'' has characteristics
similar to the three dimension cross product.  It can be verified that
it satisfies at least the following orthogonality conditions as does
the standard \R{3} cross product.

\begin{equation}\label{eqn:crossOld:160}
\begin{aligned}
\tripleprod{\Bu}{\Bv}{\Bu} &= 0 \\
\tripleprod{\Bu}{\Bv}{\Bv} &= 0 \\
      \crossprod{\Bu}{\Bu} &= \Bzero \\
      \crossprod{\Bu}{\Bv} &= -\crossprod{\Bv}{\Bu} \\
      \crossprod{\Bu}{(a\Bv + b\Bw)} &= a\crossprod{\Bu}{\Bv} + b\crossprod{\Bu}{\Bw} \\
      \crossprod{(a\Bu + b\Bv)}{\Bw} &= a\crossprod{\Bu}{\Bw} + b\crossprod{\Bv}{\Bw} \\
\tripleprod{\Bu}{\Bv}{\Bw} &= -\tripleprod{\Bu}{\Bw}{\Bv}
\end{aligned}
\end{equation}

Not all of these conditions are independent,
\(\crossprod{\Bu}{\Bv}\) is implied by \(\crossprod{\Bu}{\Bu} = -\crossprod{\Bu}{\Bu}\),
and \(\tripleprod{\Bu}{\Bv}{\Bu} = 0\) is implied since,
\begin{equation}\label{eqn:crossOld:180}
\begin{aligned}
\tripleprod{\Bu}{\Bv}{\Bu} &= -\tripleprod{\Bu}{\Bu}{\Bv} \\
                           &= -\dotprod{(\crossprod{\Bu}{\Bu})}{\Bv} \\
                           &= 0
\end{aligned}
\end{equation}
The key properties are probably the bilinearity, and the negation on exchange, but I have not yet
spent the time proving that all the rest follow.
% TODO...

\subsection{orthogonality and vector products}
I had arrived at the above result for a \R{4} cross product in a few
different ways, where this was one of the later methods.
The first ways that I arrived at this result was
by looking at orthogonality conditions and trying to extend the three
dimensional cross product in component form.  Using just the
orthogonality conditions is not enough to uniquely define a ``cross product''
even in \R{3}.

It is interesting to note that the dot product can be seen to be a statement of
the orthogonality conditions of Pythagoras law
%(the sum of
%squares of the lengths of two perpendicular line segments
%is the square of the length of the hypotonus).
\begin{equation*}
\norm{\Bu + \Bv}^2 = \norm{\Bu}^2 + \norm{\Bv}^2
\end{equation*}

In terms of components this is
\begin{equation}\label{eqn:crossOld:200}
\begin{aligned}
\norm{\Bu + \Bv}^2 &= \sum_i{(u_i + v_i)(u_i + v_i)} \\
                   &= \sum_i{{u_i}^2 + 2 u_i v_i + {v_i}^2} \\
                   &= \sum_i{{u_i}^2} + 2 \sum_i{u_i v_i} + \sum{{v_i}^2} \\
                   &= \norm{\Bu}^2 + 2 \sum_i{u_i v_i} + \norm{\Bv}^2
\end{aligned}
\end{equation}

So, if the Pythagorean condition is to hold the term, the dot product,
\begin{equation*}
\sum_i{u_i v_i}
\end{equation*}
must be zero.

The same thing can be done for the complex inner product, where
for orthogonality the term,
\begin{equation*}
\sum_i{ u_i \overline{v_i} + v_i \overline{u_i}}
\end{equation*}
must be zero.

If \(\sum_i{ u_i \overline{v_i}} = 0\), this implies
\(\overline{\sum_i{ u_i \overline{v_i}}} = \sum_i{v_i \overline{u_i}} = 0\), so the definitions of both the
complex and the real inner products arise naturally from an examination of orthogonality constraints.

The cross product is also closely related to orthogonality constraints and the \R{3}
cross product can be derived by looking specifically at these constraints.
This can be seen by
calculating the null space of a matrix with rows formed of the elements of two vectors
\(\Bu\) and \(\Bv\)

\begin{equation*}
\begin{bmatrix}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3
\end{bmatrix}
\end{equation*}

Any vector that is in the null space is not a linear combination of the two vectors and then
must be perpendicular to it.
\footnote{a proof of this should be inserted.  Note the implicit dependence on the real
inner product here.}
Row reducing this matrix gives

\begin{equation*}
\begin{bmatrix}
u_1(u_2 v_1 - u_1 v_2) & 0                      & u_1(u_2 v_3 - u_3 v_2) \\
0                      & u_2(u_2 v_1 - u_1 v_2) & u_2(u_3 v_1 - u_1 v_3)
\end{bmatrix}
\end{equation*}

Provided that \(u_1 \neq 0\), \(u_2 \neq 0\), and \(u_2 v_1 - u_1 v_2 \neq 0\), then the
fully reduced form of this matrix is
\begin{equation*}
\begin{bmatrix}
1 & 0 & (u_2 v_3 - u_3 v_2)/(u_2 v_1 - u_1 v_2) \\
0 & 1 & (u_3 v_1 - u_1 v_3)/(u_2 v_1 - u_1 v_2)
\end{bmatrix}
\end{equation*}

So
%, where \(t\) is an arbitrary constant,
the null space is composed of the set of scalar multiples of
the vector
\begin{equation*}
\begin{bmatrix}
(u_2 v_3 - u_3 v_2)/(u_2 v_1 - u_1 v_2) \\
(u_3 v_1 - u_1 v_3)/(u_2 v_1 - u_1 v_2) \\
-1
\end{bmatrix}
\end{equation*}

of which, provided the \R{3} cross product \(\crossprod{\Bu}{\Bv}\) is one of
\begin{equation*}
\begin{bmatrix}
{u_2 v_3 - u_3 v_2} \\
{u_3 v_1 - u_1 v_3} \\
{u_1 v_2 - u_2 v_1}
\end{bmatrix}
\end{equation*}

This shows that orthogonality is not enough to uniquely define the cross product.

Doing the same null space calculations in \R{n} for the two vectors \(\Bu\) and \(\Bv\) gives the
null space as the set of vectors \({\Bn}\), where \(t_i\) are all arbitrary constants and \(\Bn\) is
defined as follows

\begin{equation*}
\Bn =
t_1
\begin{bmatrix}
u_2 v_3 - u_3 v_2 \\
u_3 v_1 - u_1 v_3 \\
u_1 v_2 - u_2 v_1 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
+ t_2
\begin{bmatrix}
u_2 v_4 - u_4 v_2 \\
u_4 v_1 - u_1 v_4 \\
0 \\
u_1 v_2 - u_2 v_1 \\
0 \\
\vdots \\
0
\end{bmatrix}
\hdots + t_{n-2}
\begin{bmatrix}
u_2 v_n - u_n v_2 \\
u_n v_1 - u_1 v_n \\
0 \\
\vdots \\
0 \\
0 \\
u_1 v_2 - u_2 v_1
\end{bmatrix}
\end{equation*}

This is the set of vectors that are orthogonal to both \(\Bu\) and \(\Bv\), but at a glance
no particular vector from that
set is appealing as a choice for a vector product.

Suppose, for \R{4}, setting \(t_1 = 1\) and \(t_2 = 1\), then a vector from the
null space is

\begin{equation*}
\begin{bmatrix}
u_2 v_3 - u_3 v_2 \\
u_3 v_1 - u_1 v_3 \\
u_1 v_2 - u_2 v_1 \\
0
\end{bmatrix}
+
\begin{bmatrix}
u_2 v_4 - u_4 v_2 \\
u_4 v_1 - u_1 v_4 \\
0 \\
u_1 v_2 - u_2 v_1
\end{bmatrix}
\end{equation*}

If this is compared to what was called the \R{4} cross product above, it can be seen that
the cross product has these two terms, plus two more.

\begin{equation*}
\begin{bmatrix}
u_3 v_4 - u_4 v_3 \\
0 \\
u_4 v_1 - u_1 v_4 \\
u_1 v_3 - u_3 v_1
\end{bmatrix}
+
\begin{bmatrix}
0 \\
u_3 v_4 - u_4 v_3 \\
u_4 v_2 - u_2 v_4 \\
u_2 v_3 - u_3 v_2
\end{bmatrix}
\end{equation*}

It should be possible to form these last two terms via a linear combination
of the first two, but this has not been tried.
%\footnote{
%an exercise for the reader ;)}

\subsection{more on the cross product in four dimensions}
Going back to the original decomposition of the three dimensional
cross product, a possible higher dimensional
cross product can be defined in the same fashion
$
\Bu \cross_4 = \BP_4 D(\Bu) \BP_4 - {\BP_4}^T D(\Bu) {\BP_4}^T
$

or perhaps as some more general quantity
$
\Bu \cross_4 = G(\Bu) - G(\Bu)^T
$

but how are the \(\BP_4\) or \(G\) matrices selected, so that
the result
has properties comparable to the \R{3}
cross product.

It can be noted above that the \(\BP\) matrix above is a permutation matrix. This is the identity
matrix with its rows shifted
up by one, or it columns shifted over right by one.

In four dimensions there are three permutation matrices that be can created by similarly shifting the
rows or columns of the identity matrix.  These are

\begin{equation*}
\BP = \Mp
\end{equation*}
\begin{equation*}
\BP^2 = \Mpp
\end{equation*}
\begin{equation*}
\BP^3 = \Mppp
\end{equation*}

They matrices are unitary, so for each the inverse is the transpose
\begin{equation}\label{eqn:crossOld:220}
\begin{aligned}
{\BP}^{-1} &= {\BP}^T = \BP^3 \\
{\BP^2}^{-1} &= {\BP^2}^T = \BP^2 \\
{\BP^3}^{-1} &= {\BP^3}^T = \BP
\end{aligned}
\end{equation}

With the hopes of discovering a suitable cross product operator with the form of the \R{3}
cross product operator, calculation for \({\BP^i} D(\Bu) {\BP^i}\) follows.

\begin{equation}\label{eqn:crossOld:240}
\begin{aligned}
{\BP} D(\Bu) {\BP} &=
\Mp
\Mpu
\Mp \\
& =
\begin{bmatrix}
0 & u_2 & 0 & 0 \\
0 & 0 & u_3 & 0 \\
0 & 0 & 0 & u_4 \\
u_1 & 0 & 0 & 0
\end{bmatrix}
\Mp
=
\begin{bmatrix}
0   & 0   & u_2 & 0   \\
0   & 0   & 0   & u_3 \\
u_4 & 0   & 0   & 0   \\
0   & u_1 & 0   & 0
\end{bmatrix}
\end{aligned}
\end{equation}

\begin{equation}\label{eqn:crossOld:260}
\begin{aligned}
{\BP^2} D(\Bu) {\BP^2} &=
\Mpp
\Mpu
\Mpp \\
&=
\begin{bmatrix}
0   & 0   & u_3 & 0   \\
0   & 0   & 0   & u_4 \\
u_1 & 0   & 0   & 0   \\
0   & u_2 & 0   & 0
\end{bmatrix}
\Mpp
=
\begin{bmatrix}
u_3 & 0   & 0   & 0   \\
0   & u_4 & 0   & 0   \\
0   & 0   & u_1 & 0   \\
0   & 0   & 0   & u_2
\end{bmatrix}
\end{aligned}
\end{equation}

\begin{equation}\label{eqn:crossOld:280}
\begin{aligned}
{\BP^3} D(\Bu) {\BP^3} &=
\Mppp
\Mpu
\Mppp \\
&=
\begin{bmatrix}
0   & 0   & 0   & u_4 \\
u_1 & 0   & 0   & 0   \\
0   & u_2 & 0   & 0   \\
0   & 0   & u_3 & 0
\end{bmatrix}
\Mppp
=
\begin{bmatrix}
0   & 0   & u_4 & 0   \\
0   & 0   & 0   & u_1 \\
u_2 & 0   & 0   & 0   \\
0   & u_3 & 0   & 0
\end{bmatrix}
\end{aligned}
\end{equation}

The potential cross product operators can be defined as
\begin{equation*}
\crossop{\Bu} = {\BP^i} D(\Bu) {\BP^i} - (\BP^i)^T D(\Bu) (\BP^i)^T
\end{equation*}

For \(\BP\) the following cross product operator is generated
\begin{multline*}
\crossop{\Bu} = {\BP} D(\Bu) {\BP} - {\BP}^T D(\Bu) {\BP}^T \\
=
\begin{bmatrix}
0         & 0         & u_2 - u_4 & 0         \\
0         & 0         & 0         & u_3 - u_1 \\
u_4 - u_2 & 0         & 0         & 0         \\
0         & u_1 - u_3 & 0         & 0
\end{bmatrix}
\end{multline*}

For \(\BP^2\) a trivial cross product operator is generated
\begin{equation*}
\crossop{\Bu} = {\BP^2} D(\Bu) {\BP^2} - (\BP^2)^T D(\Bu) (\BP^2)^T = \Bzero
\end{equation*}

And the cross product generated by \(\BP^3\) is just the transpose of that
for \(\BP\)
\begin{multline*}
\crossop{\Bu} = {\BP^3} D(\Bu) {\BP^3} - (\BP^3)^T D(\Bu) (\BP^3)^T \\
=
\begin{bmatrix}
0         & 0         & u_4 - u_2 & 0         \\
0         & 0         & 0         & u_1 - u_3 \\
u_2 - u_4 & 0         & 0         & 0         \\
0         & u_3 - u_1 & 0         & 0
\end{bmatrix}
\end{multline*}

Obviously the second of these does not generate a useful cross product.  Since the other two are
transposes of each other, either of those can be chosen for investigation.
Examining the first of these relations shows that
\begin{multline*}
\crossprod{\Bu}{\Bv} = ({\BP} D(\Bu) {\BP} - {\BP}^T D(\Bu) {\BP}^T) \Bv
= \\
\begin{bmatrix}
0         & 0         & u_2 - u_4 & 0         \\
0         & 0         & 0         & u_3 - u_1 \\
u_4 - u_2 & 0         & 0         & 0         \\
0         & u_1 - u_3 & 0         & 0
\end{bmatrix}
\begin{bmatrix}
v_1 \\
v_2 \\
v_3 \\
v_4
\end{bmatrix}
=
\begin{bmatrix}
(u_2 - u_4)v_3 \\
(u_3 - u_1)v_4 \\
(u_4 - u_2)v_1 \\
(u_1 - u_3)v_2
\end{bmatrix}
\end{multline*}

One of the properties that the cross product in three dimensions had was
\(\tripleprod{\Bu}{\Bv}{\Bv} = 0\) and
\(\tripleprod{\Bu}{\Bv}{\Bu} = 0\).  Does this potential cross product have the same properties?
\begin{equation*}
\tripleprod{\Bu}{\Bv}{\Bv} =
%\\
\begin{matrix}
  &v_3 v_1(u_2 - u_4) \\
+ &v_4 v_2(u_3 - u_1) \\
+ &v_1 v_3(u_4 - u_2) \\
+ &v_2 v_4(u_1 - u_3)
\end{matrix}
=
\begin{matrix}
  & v_1 v_3 ( u_2 - u_4 + u_4 - u_2) \\
+ & v_2 v_4 ( u_3 - u_1 + u_1 - u_3) \\
\end{matrix}
= 0
\end{equation*}
\begin{equation*}
\tripleprod{\Bu}{\Bv}{\Bu} =
%\\
\begin{matrix}
  &(u_2 - u_4)v_3 u_1 \\
+ &(u_3 - u_1)v_4 u_2 \\
+ &(u_4 - u_2)v_1 u_3 \\
+ &(u_1 - u_3)v_2 u_4
\end{matrix}
=
\begin{matrix}
  &u_1 u_2 ( v_3 - v_4 ) \\
+ &u_1 u_4 ( v_2 - v_3 ) \\
+ &u_2 u_3 ( v_4 - v_1 ) \\
+ &u_3 u_4 ( v_1 - v_2 )
\end{matrix}
\neq 0
\end{equation*}

Although
\(\tripleprod{\Bu}{\Bv}{\Bv} = 0\), and
\(\tripleprod{\Bu}{\Bv}{\Bw} = -\tripleprod{\Bu}{\Bw}{\Bv}\) as the \R{3}
cross product, this product seems incomplete.  There are no
\(v_1 v_2\), \(v_1 v_4\), or \(v_2 v_3\) terms.  In
\(\tripleprod{\Bu}{\Bv}{\Bu}\) there are no
\(u_1 u_3\) or \(u_2 u_4\) terms and the result is not zero as would be expected in a cross product.
\footnote{
The fact that
\(\tripleprod{\Bu}{\Bv}{\Bu} \ne 0\) can also be viewed as a consequence
of \(\crossprod{\Bu}{\Bu} \ne 0\) for this cross product, given that
\(\tripleprod{\Bu}{\Bv}{\Bu} = -\tripleprod{\Bu}{\Bu}{\Bv} \ne 0\).
}

Some of the terms that are missing can be added to generate a cross product which satisfy the same
orthogonality conditions that are true for \R{3}.
For example a \(u_1 v_3 \xcap_1\) term and a
\(u_3 v_1 \xcap_1\) term could be added.  Similarly a \(-u_3 v_2 \xcap_1\) term and a
\(u_2 v_3 \xcap_1\) term can be added.  The result for
\(\tripleprod{\Bu}{\Bv}{\Bu} = \Bu\)
had a
\(u_1 u_4 v_2\) term that resulted from the \(u_1 v_2 \xcap_4\) term of \(\crossprod{\Bu}{\Bv}\).  If
a \(-u_4 v_2 \xcap_1\) term is added then it would have canceled out.
If terms are added until each term has a ``match'' and each term of \(\tripleprod{\Bu}{\Bv}{\Bu}\)
cancels out leaving zero then the following revised cross product is generated.

\begin{equation*}
\begin{matrix}
 &(u_2 v_3 - u_3 v_2)\xcap_1 \\
+&(u_3 v_4 - u_4 v_3)\xcap_2 \\
+&(u_4 v_1 - u_1 v_4)\xcap_3 \\
+&(u_1 v_2 - u_2 v_1)\xcap_4 \\
 & \\
+&(u_3 v_4 - u_4 v_3)\xcap_1 \\
+&(u_4 v_1 - u_1 v_4)\xcap_2 \\
+&(u_1 v_2 - u_2 v_1)\xcap_3 \\
+&(u_2 v_3 - u_3 v_2)\xcap_4 \\
 & \\
+&(u_2 v_4 - u_4 v_2)\xcap_1 \\
+&(u_3 v_1 - u_1 v_3)\xcap_2 \\
+&(u_4 v_2 - u_2 v_4)\xcap_3 \\
+&(u_1 v_3 - u_3 v_1)\xcap_4
\end{matrix}
\end{equation*}

Note that this can also written as
\begin{equation*}
\begin{matrix}
% 1, 2, 3
 &(u_2 v_3 - u_3 v_2)\xcap_1 \\
+&(u_3 v_1 - u_1 v_3)\xcap_2 \\
+&(u_1 v_2 - u_2 v_1)\xcap_3 \\
 & \\
% 2, 3, 4
+&(u_3 v_4 - u_4 v_3)\xcap_2 \\
+&(u_4 v_2 - u_2 v_4)\xcap_3 \\
+&(u_2 v_3 - u_3 v_2)\xcap_4 \\
 & \\
% 1, 2, 4
+&(u_2 v_4 - u_4 v_2)\xcap_1 \\
+&(u_4 v_1 - u_1 v_4)\xcap_2 \\
+&(u_1 v_2 - u_2 v_1)\xcap_4 \\
 & \\
% 1, 3, 4
+&(u_3 v_4 - u_4 v_3)\xcap_1 \\
+&(u_4 v_1 - u_1 v_4)\xcap_3 \\
+&(u_1 v_3 - u_3 v_1)\xcap_4
\end{matrix}
\end{equation*}
where the terms are grouped into 4 sets of the three dimensional cross products on the
\((1, 2, 3)\),
\((2, 3, 4)\),
\((1, 2, 4)\), and
\((1, 3, 4)\) subspaces.

If this is put back into the matrix form \(\crossprod{\Bu}{}\) as
\begin{equation*}
\begin{bmatrix}
  0         & - u_3 - u_4 &   u_2 - u_4 &   u_2 + u_3 \\
  u_3 + u_4 &   0         & - u_1 - u_4 &   u_3 - u_1 \\
  u_4 - u_2 &   u_1 + u_4 &   0         & - u_1 - u_2 \\
- u_2 - u_3 &   u_1 - u_3 &   u_1 + u_2 &   0
\end{bmatrix}
\begin{bmatrix}
v_1 \\
v_2 \\
v_3 \\
v_4
\end{bmatrix}
\end{equation*}

Then the left hand side is the same as obtained via the \R{4} rotation method.

%%%%%% verification calculations:
%%%%%\begin{equation*}
%%%%%\crossop{\Bu}=
%%%%%\begin{bmatrix}
%%%%%  0         & - u_3 - u_4 &   u_2 - u_4 &   u_2 + u_3 \\
%%%%%  u_3 + u_4 &   0         & - u_1 - u_4 &   u_3 - u_1 \\
%%%%%  u_4 - u_2 &   u_1 + u_4 &   0         & - u_1 - u_2 \\
%%%%%- u_2 - u_3 &   u_1 - u_3 &   u_1 + u_2 &   0
%%%%%\end{bmatrix}
%%%%%\end{equation*}
%%%%%
%%%%%\begin{equation*}
%%%%%\crossop{\Bu}= \Bv
%%%%%\begin{bmatrix}
%%%%%(  0        )v_1 +(- u_3 - u_4)v_2 +(  u_2 - u_4)v_3 +(  u_2 + u_3)v_4 \\
%%%%%(  u_3 + u_4)v_1 +(  0        )v_2 +(- u_1 - u_4)v_3 +(  u_3 - u_1)v_4 \\
%%%%%(  u_4 - u_2)v_1 +(  u_1 + u_4)v_2 +(  0        )v_3 +(- u_1 - u_2)v_4 \\
%%%%%(- u_2 - u_3)v_1 +(  u_1 - u_3)v_2 +(  u_1 + u_2)v_3 +(  0        )v_4
%%%%%\end{bmatrix}
%%%%%\end{equation*}
%%%%%
%%%%%\begin{multline*}
%%%%%\tripleprod{\Bu}{\Bv}{\Bv} = \\
%%%%%\begin{bmatrix}
%%%%%(- u_3 - u_4)v_2 v_1 +(  u_2 - u_4)v_3 v_1 +(  u_2 + u_3)v_4 v_1 \\
%%%%%(  u_3 + u_4)v_1 v_2 +(- u_1 - u_4)v_3 v_2 +(  u_3 - u_1)v_4 v_2 \\
%%%%%(  u_4 - u_2)v_1 v_3 +(  u_1 + u_4)v_2 v_3 +(- u_1 - u_2)v_4 v_3 \\
%%%%%(- u_2 - u_3)v_1 v_4 +(  u_1 - u_3)v_2 v_4 +(  u_1 + u_2)v_3 v_4
%%%%%\end{bmatrix}
%%%%%= \\
%%%%%(  u_1 + u_2)v_3 v_4 + \\
%%%%%(- u_1 - u_2)v_4 v_3 + \\
%%%%%(  u_1 + u_4)v_2 v_3 + \\
%%%%%(- u_1 - u_4)v_3 v_2 + \\
%%%%%(  u_1 - u_3)v_2 v_4 + \\
%%%%%(  u_3 - u_1)v_4 v_2 + \\
%%%%%(  u_2 + u_3)v_4 v_1 + \\
%%%%%(- u_2 - u_3)v_1 v_4 + \\
%%%%%(  u_2 - u_4)v_3 v_1 + \\
%%%%%(  u_4 - u_2)v_1 v_3 + \\
%%%%%(  u_3 + u_4)v_1 v_2 + \\
%%%%%(- u_3 - u_4)v_2 v_1 \\
%%%%%= 0
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\tripleprod{\Bu}{\Bv}{\Bu} = \\
%%%%%\begin{bmatrix}
%%%%%(- u_3 - u_4)v_2 u_1 +(  u_2 - u_4)v_3 u_1 +(  u_2 + u_3)v_4 u_1 \\
%%%%%(  u_3 + u_4)v_1 u_2 +(- u_1 - u_4)v_3 u_2 +(  u_3 - u_1)v_4 u_2 \\
%%%%%(  u_4 - u_2)v_1 u_3 +(  u_1 + u_4)v_2 u_3 +(- u_1 - u_2)v_4 u_3 \\
%%%%%(- u_2 - u_3)v_1 u_4 +(  u_1 - u_3)v_2 u_4 +(  u_1 + u_2)v_3 u_4
%%%%%\end{bmatrix} \\
%%%%% = \\
%%%%%u_1 u_2 v_3 + \\
%%%%%u_1 u_2 v_3 (-1) + \\
%%%%%u_1 u_2 v_4 + \\ + \\
%%%%%u_1 u_2 v_4 (-1) + \\
%%%%%u_1 u_3 v_2 + \\
%%%%%u_1 u_3 v_2 (-1) + \\
%%%%%u_1 u_3 v_4 + \\
%%%%%u_1 u_3 v_4 (-1) + \\
%%%%%u_1 u_4 v_2 + \\
%%%%%u_1 u_4 v_2 (-1) + \\
%%%%%u_1 u_4 v_3 + \\
%%%%%u_1 u_4 v_3 (-1) + \\
%%%%%u_2 u_3 v_1 + \\
%%%%%u_2 u_3 v_1 (-1) + \\
%%%%%u_2 u_3 v_4 + \\
%%%%%u_2 u_3 v_4 (-1) + \\
%%%%%u_2 u_4 v_1 + \\
%%%%%u_2 u_4 v_1 (-1) + \\
%%%%%u_2 u_4 v_3 + \\
%%%%%u_2 u_4 v_3 (-1) + \\
%%%%%u_3 u_4 v_1 + \\
%%%%%u_3 u_4 v_1 (-1) + \\
%%%%%u_3 u_4 v_2 + \\
%%%%%u_3 u_4 v_2 (-1) \\
%%%%% = 0
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\crossprod{\Bu}{\Bu} = \\
%%%%%\begin{bmatrix}
%%%%%(- u_3 - u_4)u_2 +(  u_2 - u_4)u_3 +(  u_2 + u_3)u_4 \\
%%%%%(  u_3 + u_4)u_1 +(- u_1 - u_4)u_3 +(  u_3 - u_1)u_4 \\
%%%%%(  u_4 - u_2)u_1 +(  u_1 + u_4)u_2 +(- u_1 - u_2)u_4 \\
%%%%%(- u_2 - u_3)u_1 +(  u_1 - u_3)u_2 +(  u_1 + u_2)u_3
%%%%%\end{bmatrix} \\
%%%%%=0
%%%%%\end{multline*}
%%%%%% end verification

\subsection{components of the \texorpdfstring{\R{4}}{4D} cross product operator}

The \R{4} cross product operator that has been defined above was
arrived at by two different methods.  One was via an \R{4} rotation, and
the second was by starting with the decomposed form of $\Bu \cross_3 =
\BP\BD\BP - (\BP\BD\BP)^T$ and adding terms until it was ``complete'' with
respect to various orthogonality conditions that hold in \R{3}.  A
additional method of arriving at the same operator can be seen by
decomposing this operator.

To do so, \(\crossop{\Bu}\) can be written
\(G(\Bu) - {G(\Bu)}^T\) where
\begin{equation}\label{eqn:crossOld:300}
\begin{aligned}
G(\Bu)
=&
\begin{bmatrix}
  0         &   0         &   u_2       &   u_2 + u_3 \\
  u_3 + u_4 &   0         &   0         &   u_3       \\
  u_4       &   u_1 + u_4 &   0         &   0         \\
  0         &   u_1       &   u_1 + u_2 &   0
\end{bmatrix} \\
=&
\begin{bmatrix}
  0         &   0         &   u_2       &   0         \\
  0         &   0         &   0         &   u_3       \\
  u_4       &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0
\end{bmatrix} \\
+&
\begin{bmatrix}
  0         &   0         &   0         &   u_3       \\
  u_4       &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0         \\
  0         &   0         &   u_2       &   0
\end{bmatrix} \\
+&
\begin{bmatrix}
  0         &   0         &   0         &   u_2       \\
  u_3       &   0         &   0         &   0         \\
  0         &   u_4       &   0         &   0         \\
  0         &   0         &   u_1       &   0
\end{bmatrix}
\end{aligned}
\end{equation}

If this is decomposed into four sets of three dimension cross product operators on each of
the subspaces where one component is removed then
\begin{equation}\label{eqn:crossOld:320}
\begin{aligned}
G(\Bu)
=&
\begin{bmatrix}
  0         &   0         &   u_2       &   0         \\
  u_3       &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0         \\
  0         &   0         &   0         &   0
\end{bmatrix} \\
 +&
\begin{bmatrix}
  0         &   0         &   0         &   0         \\
  0         &   0         &   0         &   u_3       \\
  0         &   u_4       &   0         &   0         \\
  0         &             &   u_2       &   0
\end{bmatrix} \\
+&
\begin{bmatrix}
  0         &   0         &   0         &   u_2       \\
  u_4       &   0         &   0         &   0         \\
  0         &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0
\end{bmatrix} \\
+&
\begin{bmatrix}
  0         &   0         &   0         &   u_3       \\
  0         &   0         &   0         &   0         \\
  u_4       &   0         &   0         &   0         \\
  0         &   0         &   u_1       &   0
\end{bmatrix}
\end{aligned}
\end{equation}

Thus the \R{4} cross product operator can be generated by adding all of the \R{3} cross product
operators for each subspace where one component is removed or zeroed out.

Each of the terms of the sum for \(G(\Bu)\) above can be decomposed using the
\(\BP\), \(\BP^2\), and \(\BP^3\)
permutation matrices
\begin{equation}\label{eqn:crossOld:340}
\begin{aligned}
\begin{bmatrix}
  0         &   0         &   u_2       &   0         \\
  0         &   0         &   0         &   u_3       \\
  u_4       &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0
\end{bmatrix}
&=
\Mp \Mpu \Mp \\
&=
\BP D(\Bu) \BP
\end{aligned}
\end{equation}
\begin{equation}\label{eqn:crossOld:360}
\begin{aligned}
\begin{bmatrix}
  0         &   0         &   0         &   u_3       \\
  u_4       &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   0         \\
  0         &   0         &   u_2       &   0
\end{bmatrix}
&=
\Mpp \Mpu \Mp \\
&=
\BP^2 D(\Bu) \BP
%=
%\BP \BP D(\Bu) \BP
\end{aligned}
\end{equation}
\begin{equation}\label{eqn:crossOld:380}
\begin{aligned}
\begin{bmatrix}
  0         &   0         &   0         &   u_2       \\
  u_3       &   0         &   0         &   0         \\
  0         &   u_4       &   0         &   0         \\
  0         &   0         &   u_1       &   0
\end{bmatrix}
&=
\Mp \Mpu \Mpp \\
&=
\BP D(\Bu) \BP^2
%=
%\BP D(\Bu) \BP \BP
\end{aligned}
\end{equation}

And can write in summary, that the four dimensional cross product operator is
\begin{equation*}
G(\Bu)
=
\BP D(\Bu) \BP +
\BP D(\Bu) \BP^2
+
\BP^2 D(\Bu) \BP
\end{equation*}

Defining,
\begin{equation*}
F(\Bu) = \BP D(\Bu) \BP,
\end{equation*}
the three and four dimensional cross products operator matrices can be written,

\begin{multline*}
\Bu \cross_3 =
F(\Bu) - {F(\Bu)}^T \\
\text{where}
\BP =
\begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix}
\end{multline*}
\begin{multline*}
\Bu \cross_4 =
      F(\Bu)     -         {F(\Bu)}^T \\
+ \BP F(\Bu)     -         {F(\Bu)}^T {\BP}^T
    + F(\Bu) \BP - {\BP}^T {F(\Bu)}^T
\\
\text{where}
\BP = \Mp
\end{multline*}

\subsection{possible cross products in five dimensions}
Possible cross products were constructed earlier
for which the
\(\tripleprod{\Bu}{\Bv}{\Bv} = 0\)
and for which
\(\tripleprod{\Bu}{\Bv}{\Bu}\) could possibly be zero under certain conditions, but was not true generally.
It was shown that the sum of the cross products of the 4 possible \R{3} subspaces of \R{4}
was a more suitable choice for a cross product than the other construction as it generates a
result that is orthogonal to both of its component vectors.  That result could have been obtained
more directly, but the process used to arrive at it indirectly was useful or at least interesting.

Let us form the sum of the \R{4} cross products of the five possible \R{4} subspaces of \R{5} and see what the result is.
It will be simpler to use just the positive parts of the \R{4} cross product operator,
then to expand this all out explicitly.

For the \((1,2,3,4)\) subspace
\begin{equation*}
\begin{bmatrix}
  0         &   0         &   u_2       &   u_2 + u_3 &   0         \\
  u_3 + u_4 &   0         &   0         &   u_3       &   0         \\
  u_4       &   u_1 + u_4 &   0         &   0         &   0         \\
  0         &   u_1       &   u_1 + u_2 &   0         &   0         \\
  0         &   0         &   0         &   0         &   0
\end{bmatrix}
\end{equation*}
For the \((1,2,3,5)\) subspace
\begin{equation*}
\begin{bmatrix}
  0         &   0         &   u_2       &   0         &   u_2 + u_3 \\
  u_3 + u_5 &   0         &   0         &   0         &   u_3       \\
  u_5       &   u_1 + u_5 &   0         &   0         &   0         \\
  0         &   0         &   0         &   0         &   0         \\
  0         &   u_1       &   u_1 + u_2 &   0         &   0
\end{bmatrix}
\end{equation*}
For the \((1,2,4,5)\) subspace
\begin{equation*}
\begin{bmatrix}
  0         &   0         &   0         &   u_2       &   u_2 + u_4 \\
  u_4 + u_5 &   0         &   0         &   0         &   u_4       \\
  0         &   0         &   0         &   0         &   0         \\
  u_5       &   u_1 + u_5 &   0         &   0         &   0         \\
  0         &   u_1       &   0         &   u_1 + u_2 &   0
\end{bmatrix}
\end{equation*}
For the \((1,3,4,5)\) subspace
\begin{equation*}
\begin{bmatrix}
  0         &   0         &   0         &   u_3       &   u_3 + u_4 \\
  0         &   0         &   0         &   0         &   0         \\
  u_4 + u_5 &   0         &   0         &   0         &   u_4       \\
  u_5       &   0         &   u_1 + u_5 &   0         &   0         \\
  0         &   0         &   u_1       &   u_1 + u_3 &   0
\end{bmatrix}
\end{equation*}
For the \((2,3,4,5)\) subspace
\begin{equation*}
\begin{bmatrix}
  0         & 0         &   0         &   0         &   0         \\
  0         & 0         &   0         &   u_3       &   u_3 + u_4 \\
  0         & u_4 + u_5 &   0         &   0         &   u_4       \\
  0         & u_5       &   u_2 + u_5 &   0         &   0         \\
  0         & 0         &   u_2       &   u_2 + u_3 &   0
\end{bmatrix}
\end{equation*}

%\begin{bmatrix}
%  0         &   0         &   u_2       &   u_2 + u_3 &   0         \\
%  0         &   0         &   u_2       &   0         &   u_2 + u_3 \\
%  0         &   0         &   0         &   u_2       &   u_2 + u_4 \\
%  0         &   0         &   0         &   u_3       &   u_3 + u_4 \\
%  0         &   0         &   0         &   0         &   0         \\
%----------------------------------------------------------------------
%  0         &   0         &   2 u_2     &   2 u_2     &   2 u_2     \\
%                                          + 2 u_3       + 2 u_3
%                                                        + 2 u_4
%----------------------------------------------------------------------
%  0         &   0         &   2 u_2     & 2 u_2 +2u_3&2u_2+2u_3+2u_4 \\
%
%
%  u_3 + u_4 &   0         &   0         &   u_3       &   0         \\
%  u_3 + u_5 &   0         &   0         &   0         &   u_3       \\
%  u_4 + u_5 &   0         &   0         &   0         &   u_4       \\
%  0         &   0         &   0         &   0         &   0         \\
%  0         &   0         &   0         &   u_3       &   u_3 + u_4 \\
%----------------------------------------------------------------------
%  2 u_3     &   0         &   0         &   2 u_3     &   2 u_3     \\
%+ 2 u_4                                                 + 2 u_4
%+ 2 u_5
%----------------------------------------------------------------------
%2u_3+2u_4+2u_5& 0         &   0         &   2 u_3     &   2 u_3 +2u_4    \\
%
%
%  u_4       &   u_1 + u_4 &   0         &   0         &   0         \\
%  u_5       &   u_1 + u_5 &   0         &   0         &   0         \\
%  0         &   0         &   0         &   0         &   0         \\
%  u_4 + u_5 &   0         &   0         &   0         &   u_4       \\
%  0         &   u_4 + u_5 &   0         &   0         &   u_4       \\
%----------------------------------------------------------------------
%  2 u_4     &   2 u_4     &   0         &   0         &   2 u_4     \\
%+ 2 u_5       + 2 u_5
%              + 2 u_1
%----------------------------------------------------------------------
%  2 u_4+2u_5&2u_1+2u_4+2u_5 &  0        &   0         &   2 u_4     \\
%
%
%  0         &   u_1       &   u_1 + u_2 &   0         &   0         \\
%  0         &   0         &   0         &   0         &   0         \\
%  u_5       &   u_1 + u_5 &   0         &   0         &   0         \\
%  u_5       &   0         &   u_1 + u_5 &   0         &   0         \\
%  0         &   u_5       &   u_2 + u_5 &   0         &   0         \\
%----------------------------------------------------------------------
%  2 u_5     &   2 u_1     &   2 u_1     &   0         &   0         \\
%              + 2 u_5     & + 2 u_2                                 \\
%                            + 2 u_5                                 \\
%----------------------------------------------------------------------
%  2 u_5     & 2 u_1 + 2u_5&2u_1+2u_2+2u_5&  0         &   0         \\
%
%
%  0         &   0         &   0         &   0         &   0
%  0         &   u_1       &   u_1 + u_2 &   0         &   0
%  0         &   u_1       &   0         &   u_1 + u_2 &   0
%  0         &   0         &   u_1       &   u_1 + u_3 &   0
%  0         &   0         &   u_2       &   u_2 + u_3 &   0
%----------------------------------------------------------------------
%  0         &   2 u_1     &  2u_1+2u_2  &2u_1+2u_2+2u_3 &   0
%\end{bmatrix}
%
%
%
%Adding these yields (too wide to fit across one line)
%\begin{bmatrix}
%0                     & 0                     &         2 u_2         &         2 u_2 + 2 u_3 & 2 u_2 + 2 u_3 + 2 u_4 \\
%2 u_3 + 2 u_4 + 2 u_5 & 0                     & 0                     &         2 u_3         &         2 u_3 + 2 u_4 \\
%        2 u_4 + 2 u_5 & 2 u_1 + 2 u_4 + 2 u_5 & 0                     & 0                     &                 2 u_4 \\
%                2 u_5 & 2 u_1 +         2 u_5 & 2 u_1 + 2 u_2 + 2 u_5 & 0                     & 0                     \\
%0                     & 2 u_1                 & 2 u_1 + 2 u_2         & 2 u_1 + 2 u_2 + 2 u_3 & 0
%\end{bmatrix}
%
%
%
%Adding these yields (where the first matrix is the first three columns and the second is the last two)
%\begin{multline*}
%\begin{bmatrix}
%%0                     & 0                     &         2 u_2         &\\
%2 u_3 + 2 u_4 + 2 u_5 & 0                     & 0                     &\\
%        2 u_4 + 2 u_5 & 2 u_1 + 2 u_4 + 2 u_5 & 0                     &\\
%                2 u_5 & 2 u_1 +         2 u_5 & 2 u_1 + 2 u_2 + 2 u_5 &\\
%0                     & 2 u_1                 & 2 u_1 + 2 u_2         &
%\end{bmatrix} \\
%\begin{bmatrix}
%&         2 u_2 + 2 u_3 & 2 u_2 + 2 u_3 + 2 u_4 \\
%&         2 u_3         &         2 u_3 + 2 u_4 \\
%& 0                     &                 2 u_4 \\
%& 0                     & 0                     \\
%& 2 u_1 + 2 u_2 + 2 u_3 & 0
%\end{bmatrix}
%\end{multline*}

Which sums to the following
\begin{equation}\label{eqn:crossOld:400}
\begin{aligned}
2&
\begin{bmatrix}
0                     & 0                     &           u_2         &           u_2 +   u_3 &   u_2 +   u_3 +   u_4 \\
  u_3 +   u_4 +   u_5 & 0                     & 0                     &           u_3         &           u_3 +   u_4 \\
          u_4 +   u_5 &   u_1 +   u_4 +   u_5 & 0                     & 0                     &                   u_4 \\
                  u_5 &   u_1 +           u_5 &   u_1 +   u_2 +   u_5 & 0                     & 0                     \\
0                     &   u_1                 &   u_1 +   u_2         &   u_1 +   u_2 +   u_3 & 0
\end{bmatrix} \\
=&
2
\begin{bmatrix}
 0   & 0   & 0   & 0   & u_2 \\
 u_3 & 0   & 0   & 0   & 0 \\
 0   & u_4 & 0   & 0   & 0 \\
 0   & 0   & u_5 & 0   & 0 \\
 0   & 0   & 0   & u_1 & 0
\end{bmatrix}
+2
\begin{bmatrix}
 0   & 0   & 0   & 0   & u_3 \\
 u_4 & 0   & 0   & 0   & 0 \\
 0   & u_5 & 0   & 0   & 0 \\
 0   & 0   & u_1 & 0   & 0 \\
 0   & 0   & 0   & u_2 & 0
\end{bmatrix} \\
+&2
\begin{bmatrix}
 0   & 0   & 0   & 0   & u_4 \\
 u_5 & 0   & 0   & 0   & 0 \\
 0   & u_1 & 0   & 0   & 0 \\
 0   & 0   & u_2 & 0   & 0 \\
 0   & 0   & 0   & u_3 & 0
\end{bmatrix}
+2
\begin{bmatrix}
 0   & 0   & 0   & u_2 & 0 \\
 0   & 0   & 0   & 0   & u_3 \\
 u_4 & 0   & 0   & 0   & 0 \\
 0   & u_5 & 0   & 0   & 0 \\
 0   & 0   & u_1 & 0   & 0
\end{bmatrix} \\
+&2
\begin{bmatrix}
 0   & 0   & 0   & u_3 & 0 \\
 0   & 0   & 0   & 0   & u_4 \\
 u_5 & 0   & 0   & 0   & 0 \\
 0   & u_1 & 0   & 0   & 0 \\
 0   & 0   & u_2 & 0   & 0
\end{bmatrix}
+2
\begin{bmatrix}
 0   & 0   & u_2 & 0   & 0 \\
 0   & 0   & 0   & u_3 & 0 \\
 0   & 0   & 0   & 0   & u_4 \\
 u_5 & 0   & 0   & 0   & 0 \\
 0   & u_1 & 0   & 0   & 0
\end{bmatrix}
\end{aligned}
\end{equation}

If \(\BP\) is defined as
\begin{equation*}
\begin{bmatrix}
 0 & 1 & 0 & 0 & 0 \\
 0 & 0 & 1 & 0 & 0 \\
 0 & 0 & 0 & 1 & 0 \\
 0 & 0 & 0 & 0 & 1 \\
 1 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{equation*}
then the \R{5} cross product operator can be written as
\begin{equation*}
\Bu \cross_5 = G(\Bu) - {G(\Bu)}^T
\end{equation*}
where
\begin{multline*}
G(\Bu) = 2 (
\BP D(\Bu) \BP
+ \BP D(\Bu) \BP^2
+ \BP^2 D(\Bu) \BP^2
+ \BP^2 D(\Bu) \BP \\
+ \BP D(\Bu) \BP^3
+ \BP^3 D(\Bu) \BP
)
\end{multline*}

Reiterating the results for each of
\R{3},
\R{4}, and
\R{5}, where \(\BD = D(\Bu)\)

\begin{equation*}
\Bu \cross_3 =
\BP\BD\BP
-
(\BP\BD\BP)^T
\end{equation*}
\begin{equation*}
\BP =
\begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix}
\end{equation*}
\begin{equation*}
\Bu \cross_4 =
\BP\BD\BP + \BP\BD\BP^2 + \BP^2\BD\BP
-
(\BP\BD\BP + \BP\BD\BP^2 + \BP^2\BD\BP)^T
\end{equation*}
\begin{equation*}
\BP = \Mp
\end{equation*}
\begin{multline*}
\Bu \cross_5 =
2 (
  \BP\BD\BP
+ \BP\BD\BP^2
+ \BP^2\BD\BP^2
+ \BP^2\BD\BP
+ \BP\BD\BP^3
+ \BP^3\BD\BP
)
- \\
2 (
  \BP\BD\BP
+ \BP\BD\BP^2
+ \BP^2\BD\BP^2
+ \BP^2\BD\BP
+ \BP\BD\BP^3
+ \BP^3\BD\BP
)^T
\end{multline*}
\begin{equation*}
\BP =
\begin{bmatrix}
 0 & 1 & 0 & 0 & 0 \\
 0 & 0 & 1 & 0 & 0 \\
 0 & 0 & 0 & 1 & 0 \\
 0 & 0 & 0 & 0 & 1 \\
 1 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{equation*}

There is a definite pattern here.  Looking at the positive parts, this pattern can extrapolated to higher dimensions
\begin{equation}\label{eqn:crossOld:420}
\begin{aligned}
\BR^3 : &\PDP{1}{1} \\
\BR^4 : &\PDP{1}{1} + \PDP{1}{2} \\
      + &\PDP{2}{1} \\
\BR^5 : &\PDP{1}{1} + \PDP{1}{2} + \PDP{1}{3} \\
      + &\PDP{2}{1} + \PDP{2}{2} \\
      + &\PDP{3}{1} \\
\BR^6 : &\PDP{1}{1} + \PDP{1}{2} + \PDP{1}{3} + \PDP{1}{4} \\
      + &\PDP{2}{1} + \PDP{2}{2} + \PDP{2}{3} \\
      + &\PDP{3}{1} + \PDP{3}{2} \\
      + &\PDP{4}{1} \\
\BR^7 : &\hdots
\end{aligned}
\end{equation}
In the above all of the sets of \(\PDP{i}{j}\) have been included such that \(i+j < n\), the dimension of the
vector space.  The number of these matrices is \(\sum_{i=1}^{n-2}{i} = \frac{1}{2}(n-2)(n-1)\).
Because of the way these operators have been constructed, for \(\Bu \cross\)
in \R{4} there are \((4) (3) = 12 \) positive terms (in \R{3} there are \(3\) positive terms),
in \R{5} there are \((5) (12)\) positive terms, and
in \R{n} it can be expected that there will be \((n) (n-1) ... (3) = n!/2\) positive terms.

Each of the matrices \(\PDP{i}{j}\) contributes \(n\) positive terms to
the cross product, and so the following multiplicative factor can be added to the terms above
to have a definition consistent with the \R{5} cross product operator derived above.
\begin{equation*}
\frac{\frac{1}{n}\frac{n!}{2}}{\frac{1}{2}(n-2)(n-1)} = (n-3)!
\end{equation*}

Using this pattern, the general cross product operator matrix for \R{n} can be written as
\begin{equation}\label{eqn:crossOld:440}
\begin{aligned}
\Bu \cross_n &= (n-3)! \sum_{i=1}^{n-2}\sum_{j=1}^{n-1-i}(\PDP{i}{j} - (\PDP{i}{j})^T)
\\
%\end{equation*}
%\begin{equation*}
\text{where}\:
\BP &=
\begin{bmatrix}
0 & 1 & 0 & \hdots & 0 \\
0 & 0 & 1 & 0      & 0 \\
0 & 0 & 0 & \ddots & 0 \\
0 & 0 & 0 & 0      & 1 \\
1 & 0 & 0 & \hdots & 0
\end{bmatrix}
\\
%\end{equation*}
%\begin{equation*}
\text{and}\:
\BD &=
\begin{bmatrix}
u_1 & 0   & \hdots & 0       & 0 \\
0   & u_2 & 0      & 0       & 0 \\
0   & 0   & \ddots & 0       & 0 \\
0   & 0   & 0      & u_{n-1} & 0 \\
0   & 0   & \hdots & 0       & u_n
\end{bmatrix}
\end{aligned}
\end{equation}

Note that for higher than \R{5} it has not yet been verified that
\(\tripleprod{\Bu}{\Bv}{\Bu} = 0\)
or that
\(\tripleprod{\Bu}{\Bv}{\Bv} = 0\)
or that
\(\crossprod{\Bu}{\Bu} = \Bzero\)
.  These have been verified explicitly for \R{4} and \R{5}, but the calculations are too tedious to show.

%%%%%% verification:
%%%%%\subsection{validity check for generalized cross product operator}
%%%%%
%%%%%For \R{5} let us calculate \(\crossprod{\Bu}{\Bv}\) and see if this is orthogonal to both \(\Bu\) and \(\Bv\),
%%%%%and see if \(\crossprod{\Bu}{\Bu} = 0\).
%%%%%\begin{multline*}
%%%%%\frac{1}{2} \Bu \cross_5 = \\
%%%%%\begin{bmatrix}
%%%%% 0           &-u_3-u_4-u_5 & u_2-u_4-u_5 & u_2+u_3-u_5 & u_2+u_3+u_4 \\
%%%%% u_3+u_4+u_5 & 0           &-u_1-u_4-u_5 & u_3-u_1-u_5 & u_3+u_4-u_1 \\
%%%%% u_4+u_5-u_2 & u_1+u_4+u_5 & 0           &-u_1-u_2-u_5 & u_4-u_1-u_2 \\
%%%%% u_5-u_2-u_3 & u_1+u_5-u_3 & u_1+u_2+u_5 & 0           &-u_1-u_2-u_3 \\
%%%%%-u_2-u_3-u_4 & u_1-u_3-u_4 & u_1+u_2-u_4 & u_1+u_2+u_3 & 0
%%%%%\end{bmatrix}
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\frac{1}{2} \Bu \cross_5 \Bv = \\
%%%%%\begin{bmatrix}
%%%%%(-u_3-u_4-u_5)v_2 +( u_2-u_4-u_5)v_3 +( u_2+u_3-u_5)v_4 +( u_2+u_3+u_4)v_5 \\
%%%%%( u_3+u_4+u_5)v_1 +(-u_1-u_4-u_5)v_3 +( u_3-u_1-u_5)v_4 +( u_3+u_4-u_1)v_5 \\
%%%%%( u_4+u_5-u_2)v_1 +( u_1+u_4+u_5)v_2 +(-u_1-u_2-u_5)v_4 +( u_4-u_1-u_2)v_5 \\
%%%%%( u_5-u_2-u_3)v_1 +( u_1+u_5-u_3)v_2 +( u_1+u_2+u_5)v_3 +(-u_1-u_2-u_3)v_5 \\
%%%%%(-u_2-u_3-u_4)v_1 +( u_1-u_3-u_4)v_2 +( u_1+u_2-u_4)v_3 +( u_1+u_2+u_3)v_4
%%%%%\end{bmatrix}
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\frac{1}{2} \Bu \cross_5 \Bv \cdot \Bv = \\
%%%%%(-u_3-u_4-u_5)v_2 v_1 +( u_2-u_4-u_5)v_3 v_1 +( u_2+u_3-u_5)v_4 v_1 +( u_2+u_3+u_4)v_5 v_1 \\
%%%%%( u_3+u_4+u_5)v_1 v_2 +(-u_1-u_4-u_5)v_3 v_2 +( u_3-u_1-u_5)v_4 v_2 +( u_3+u_4-u_1)v_5 v_2 \\
%%%%%( u_4+u_5-u_2)v_1 v_3 +( u_1+u_4+u_5)v_2 v_3 +(-u_1-u_2-u_5)v_4 v_3 +( u_4-u_1-u_2)v_5 v_3 \\
%%%%%( u_5-u_2-u_3)v_1 v_4 +( u_1+u_5-u_3)v_2 v_4 +( u_1+u_2+u_5)v_3 v_4 +(-u_1-u_2-u_3)v_5 v_4 \\
%%%%%(-u_2-u_3-u_4)v_1 v_5 +( u_1-u_3-u_4)v_2 v_5 +( u_1+u_2-u_4)v_3 v_5 +( u_1+u_2+u_3)v_4 v_5 \\
%%%%%= \\
%%%%%v_1 v_2( u_3+u_4+u_5)) + \\
%%%%%v_1 v_2(-u_3-u_4-u_5)) + \\
%%%%%v_1 v_3( u_2-u_4-u_5)) + \\
%%%%%v_1 v_3( u_4+u_5-u_2)) + \\
%%%%%v_1 v_4( u_2+u_3-u_5)) + \\
%%%%%v_1 v_4( u_5-u_2-u_3)) + \\
%%%%%v_1 v_5( u_2+u_3+u_4)) + \\
%%%%%v_1 v_5(-u_2-u_3-u_4)) + \\
%%%%%v_2 v_3( u_1+u_4+u_5)) + \\
%%%%%v_2 v_3(-u_1-u_4-u_5)) + \\
%%%%%v_2 v_4( u_1+u_5-u_3)) + \\
%%%%%v_2 v_4( u_3-u_1-u_5)) + \\
%%%%%v_2 v_5( u_1-u_3-u_4)) + \\
%%%%%v_2 v_5( u_3+u_4-u_1)) + \\
%%%%%v_3 v_4( u_1+u_2+u_5)) + \\
%%%%%v_3 v_4(-u_1-u_2-u_5)) + \\
%%%%%v_3 v_5( u_1+u_2-u_4)) + \\
%%%%%v_3 v_5( u_4-u_1-u_2)) + \\
%%%%%v_4 v_5( u_1+u_2+u_3)) + \\
%%%%%v_4 v_5(-u_1-u_2-u_3)) \\
%%%%%= 0
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\frac{1}{2} \Bu \cross_5 \Bv \cdot \Bu = \\
%%%%%(-u_3-u_4-u_5)v_2 u_1 +( u_2-u_4-u_5)v_3 u_1 +( u_2+u_3-u_5)v_4 u_1 +( u_2+u_3+u_4)v_5 u_1 \\
%%%%%( u_3+u_4+u_5)v_1 u_2 +(-u_1-u_4-u_5)v_3 u_2 +( u_3-u_1-u_5)v_4 u_2 +( u_3+u_4-u_1)v_5 u_2 \\
%%%%%( u_4+u_5-u_2)v_1 u_3 +( u_1+u_4+u_5)v_2 u_3 +(-u_1-u_2-u_5)v_4 u_3 +( u_4-u_1-u_2)v_5 u_3 \\
%%%%%( u_5-u_2-u_3)v_1 u_4 +( u_1+u_5-u_3)v_2 u_4 +( u_1+u_2+u_5)v_3 u_4 +(-u_1-u_2-u_3)v_5 u_4 \\
%%%%%(-u_2-u_3-u_4)v_1 u_5 +( u_1-u_3-u_4)v_2 u_5 +( u_1+u_2-u_4)v_3 u_5 +( u_1+u_2+u_3)v_4 u_5 \\
%%%%%= \\
%%%%%(-u_3-u_4-u_5)v_2 u_1 + \\
%%%%%(+u_2-u_4-u_5)v_3 u_1 + \\
%%%%%(+u_2+u_3-u_5)v_4 u_1 + \\
%%%%%(+u_2+u_3+u_4)v_5 u_1 + \\
%%%%%(+u_3+u_4+u_5)v_1 u_2 + \\
%%%%%(-u_1-u_4-u_5)v_3 u_2 + \\
%%%%%(+u_3-u_1-u_5)v_4 u_2 + \\
%%%%%(+u_3+u_4-u_1)v_5 u_2 + \\
%%%%%(+u_4+u_5-u_2)v_1 u_3 + \\
%%%%%(+u_1+u_4+u_5)v_2 u_3 + \\
%%%%%(-u_1-u_2-u_5)v_4 u_3 + \\
%%%%%(+u_4-u_1-u_2)v_5 u_3 + \\
%%%%%(+u_5-u_2-u_3)v_1 u_4 + \\
%%%%%(+u_1+u_5-u_3)v_2 u_4 + \\
%%%%%(+u_1+u_2+u_5)v_3 u_4 + \\
%%%%%(-u_1-u_2-u_3)v_5 u_4 + \\
%%%%%(-u_2-u_3-u_4)v_1 u_5 + \\
%%%%%(+u_1-u_3-u_4)v_2 u_5 + \\
%%%%%(+u_1+u_2-u_4)v_3 u_5 + \\
%%%%%(+u_1+u_2+u_3)v_4 u_5 + \\
%%%%%= \\
%%%%%u_1 u_2 v_3 + \\
%%%%%u_1 u_2 v_4 + \\
%%%%%u_1 u_2 v_5 + \\
%%%%%u_1 u_2(-1) v_3 + \\
%%%%%u_1 u_2(-1) v_4 + \\
%%%%%u_1 u_2(-1) v_5 + \\
%%%%%u_1 u_3 v_2 + \\
%%%%%u_1 u_3 v_4 + \\
%%%%%u_1 u_3 v_5 + \\
%%%%%u_1 u_3(-1) v_2 + \\
%%%%%u_1 u_3(-1) v_4 + \\
%%%%%u_1 u_3(-1) v_5 + \\
%%%%%u_1 u_4 v_2 + \\
%%%%%u_1 u_4 v_3 + \\
%%%%%u_1 u_4 v_5 + \\
%%%%%u_1 u_4(-1) v_2 + \\
%%%%%u_1 u_4(-1) v_3 + \\
%%%%%u_1 u_4(-1) v_5 + \\
%%%%%u_1 u_5 v_2 + \\
%%%%%u_1 u_5 v_3 + \\
%%%%%u_1 u_5 v_4 + \\
%%%%%u_1 u_5(-1) v_2 + \\
%%%%%u_1 u_5(-1) v_3 + \\
%%%%%u_1 u_5(-1) v_4 + \\
%%%%%u_2 u_3 v_1 + \\
%%%%%u_2 u_3 v_4 + \\
%%%%%u_2 u_3 v_5 + \\
%%%%%u_2 u_3(-1) v_1 + \\
%%%%%u_2 u_3(-1) v_4 + \\
%%%%%u_2 u_3(-1) v_5 + \\
%%%%%u_2 u_4 v_1 + \\
%%%%%u_2 u_4 v_3 + \\
%%%%%u_2 u_4 v_5 + \\
%%%%%u_2 u_4(-1) v_1 + \\
%%%%%u_2 u_4(-1) v_3 + \\
%%%%%u_2 u_4(-1) v_5 + \\
%%%%%u_2 u_5 v_1 + \\
%%%%%u_2 u_5 v_3 + \\
%%%%%u_2 u_5 v_4 + \\
%%%%%u_2 u_5(-1) v_1 + \\
%%%%%u_2 u_5(-1) v_3 + \\
%%%%%u_2 u_5(-1) v_4 + \\
%%%%%u_3 u_4 v_1 + \\
%%%%%u_3 u_4 v_2 + \\
%%%%%u_3 u_4 v_5 + \\
%%%%%u_3 u_4(-1) v_1 + \\
%%%%%u_3 u_4(-1) v_2 + \\
%%%%%u_3 u_4(-1) v_5 + \\
%%%%%u_3 u_5 v_1 + \\
%%%%%u_3 u_5 v_2 + \\
%%%%%u_3 u_5 v_4 + \\
%%%%%u_3 u_5(-1) v_1 + \\
%%%%%u_3 u_5(-1) v_2 + \\
%%%%%u_3 u_5(-1) v_4 + \\
%%%%%u_4 u_5 v_1 + \\
%%%%%u_4 u_5 v_2 + \\
%%%%%u_4 u_5 v_3 + \\
%%%%%u_4 u_5(-1) v_1 + \\
%%%%%u_4 u_5(-1) v_2 + \\
%%%%%u_4 u_5(-1) v_3
%%%%%\end{multline*}
%%%%%
%%%%%\begin{multline*}
%%%%%\frac{1}{2} \Bu \cross_5 \Bu = \\
%%%%%\begin{bmatrix}
%%%%%(-u_3-u_4-u_5)u_2 +( u_2-u_4-u_5)u_3 +( u_2+u_3-u_5)u_4 +( u_2+u_3+u_4)u_5 \\
%%%%%( u_3+u_4+u_5)u_1 +(-u_1-u_4-u_5)u_3 +( u_3-u_1-u_5)u_4 +( u_3+u_4-u_1)u_5 \\
%%%%%( u_4+u_5-u_2)u_1 +( u_1+u_4+u_5)u_2 +(-u_1-u_2-u_5)u_4 +( u_4-u_1-u_2)u_5 \\
%%%%%( u_5-u_2-u_3)u_1 +( u_1+u_5-u_3)u_2 +( u_1+u_2+u_5)u_3 +(-u_1-u_2-u_3)u_5 \\
%%%%%(-u_2-u_3-u_4)u_1 +( u_1-u_3-u_4)u_2 +( u_1+u_2-u_4)u_3 +( u_1+u_2+u_3)u_4
%%%%%\end{bmatrix}
%%%%%= 0
%%%%%\end{multline*}
%%%%%% end verification.

One additional property that holds for the three dimensional cross product
that also holds for the \R{n} version is
\(\tripleprod{\Bu}{\Bv}{\Bw} = -\tripleprod{\Bu}{\Bw}{\Bv}\).
If \(\crossprod{\Bu}{\Bu} = 0\) is true for the \R{n} cross product
defined above, then this implies that
\(\tripleprod{\Bu}{\Bv}{\Bu} = 0\) too.  This first property can be shown by
writing \(\crossop{\Bu} = \BG - {\BG}^T = [g_{ij}]\), so that

\begin{equation*}
(\crossprod{\Bu}{\Bv})_i = \sum_{s=1}^{n}{g_{is}v_s}
\end{equation*}

thus for the triple-product
\begin{equation}\label{eqn:crossOld:460}
\begin{aligned}
\tripleprod{\Bu}{\Bv}{\Bw} &= \sum_{t=1}^{n}{(\sum_{s=1}^{n}g_{ts}v_s)w_t} \\
                           &= \sum_{s=1}^{n}{(\sum_{t=1}^{n}g_{ts}w_t)v_s} \\
			   &= \dotprod{{([g_{ij}]}^T \Bw)}{\Bv} \\
			   &= \dotprod{(\BG-\BG^T)^T \Bw}{\Bv} \\
			   &= -\dotprod{(\BG-\BG^T) \Bw}{\Bv} \\
			   &= -\tripleprod{\Bu}{\Bw}{\Bv}
\end{aligned}
\end{equation}

I suspect that \(\crossprod{\Bu}{\Bu} = \Bzero\) and that \(\tripleprod{\Bu}{\Bv}{\Bv} = 0\) also hold for \(n>5\) in the \R{n} cross product as defined above.
Some sort of recursive proof for this is probably required to show this.

\subsection{on the magnitude of the cross product operator}

The orthogonality properties of the cross product operator are not the only
ones of interest, since the cross product in \R{3} has a specific
magnitude as well as direction.

The projective form
\(\crossprod{\Bu}{\Bv} = \norm{\Bu}\norm{\Bv}\sin(\Bu,\Bv) \ncap\) may give
some indication of what to expect for \R{n}, where \((\Bu,\Bv)\) is the
angle between the two vectors \(\Bu\) and \(\Bv\), and \(\ncap\) is a unit
vector in the direction of \(\crossprod{\Bu}{\Bv}\).  However, how would the
angle be defined for \R{n}.

For this we can go to the projective form of the dot product
\(\dotprod{\Bu}{\Bv} = \norm{\Bu}\norm{\Bv}\cos(\Bu,\Bv)\).

Note that this form of the dot product comes directly from the
triangle law of trigonometry.

\begin{equation}\label{eqn:crossOld:480}
\begin{aligned}
\norm{\Bu - \Bv}^2 &= \norm{\Bu}^2 + \norm{\Bv}^2 -2\norm{\Bu}\norm{\Bv}\cos(\Bu,\Bv) \\
                  &= \innerprod{\Bu-\Bv}{\Bu-\Bv} \\
                  &=
		  \innerprod{\Bu}{\Bu}
		  +\innerprod{\Bv}{\Bv}
		  -\innerprod{\Bu}{\Bv}
		  -\innerprod{\Bv}{\Bu} \\
                  &= \norm{\Bu}^2 + \norm{\Bv}^2 -\innerprod{\Bu}{\Bv} -\innerprod{\Bv}{\Bu}
\end{aligned}
\end{equation}

The result follows, since for the real case, \(\innerprod{\Bu}{\Bv} + \innerprod{\Bv}{\Bu} = 2\dotprod{\Bu}{\Bv}\).

If \(\cos(\Bu,\Bv) = \frac{\dotprod{\Bu}{\Bv}}{\norm{\Bu}\norm{\Bv}}\) is taken to implicitly define the
angle between two vectors in \R{n}, then the magnitude of the \R{n} cross product could be defined in
the following fashion as is true for \R{3}

\begin{equation}\label{eqn:crossOld:500}
\begin{aligned}
\norm{\crossprod{\Bu}{\Bv}}^2
&=
\norm{\Bu}^2\norm{\Bv}^2
\lr{
1-
\lr{
\frac{\dotprod{\Bu}{\Bv}}{\norm{\Bu}\norm{\Bv}}
}^2
} \\
&= \norm{\Bu}^2\norm{\Bv}^2 - (\dotprod{\Bu}{\Bv})^2
\end{aligned}
\end{equation}

Note
that using the norm squared as a measure of magnitude looses the sign of the magnitude.  There may be
a better way of defining \(\sin(\Bu,\Bv) = \sqrt{1 - \frac{\dotprod{\Bu}{\Bv}}{\norm{\Bu}\norm{\Bv}}}\)
because this has an implied sign ambiguity.  Then again the \(\ncap\) term has also been ignored, so
perhaps the positive root is an acceptable angular measure.

I still need to check if this is true for the \R{n} cross product operator as defined above for \(n>3\).
In order to calculate
\(\norm{\Bu \cross_n \Bv}^2\)
the following sum has to be evaluated

\begin{multline*}
((n-3)!)^2
\Bigl(
\sum_{i=1}^{n-2}\sum_{j=1}^{n-1-i}(\PDP{i}{j}\Bv - (\PDP{i}{j})^T\Bv)
\Bigr)
\cdot \\
\Bigl(
\sum_{i'=1}^{n-2}\sum_{j'=1}^{n-1-i'}(\PDP{i'}{j'}\Bv - (\PDP{i'}{j'})^T\Bv)
\Bigr)
\end{multline*}

The dot product can be brought into the sum
\begin{multline*}
((n-3)!)^2
\sum_{i=1}^{n-2}\sum_{j=1}^{n-1-i}
\sum_{i'=1}^{n-2}\sum_{j'=1}^{n-1-i'}
\Bigl(
(\PDP{i}{j}\Bv - (\PDP{i}{j})^T\Bv)
\\
\cdot
(\PDP{i'}{j'}\Bv - (\PDP{i'}{j'})^T\Bv)
\Bigr)
\end{multline*}

and this can be expanded
\begin{multline*}
((n-3)!)^2
\sum_{i=1}^{n-2}\sum_{j=1}^{n-1-i}
\sum_{i'=1}^{n-2}\sum_{j'=1}^{n-1-i'} \\
  \dotprod
   {\PDP{i}{j}\Bv}
   {\PDP{i'}{j'}\Bv}
 -\dotprod
   {\PDP{i}{j}\Bv}
   {(\PDP{i'}{j'})^T\Bv} \\
 +\dotprod
   {(\PDP{i}{j})^T\Bv}
   {(\PDP{i'}{j'})^T\Bv}
 -\dotprod
   {(\PDP{i}{j})^T\Bv}
   {\PDP{i'}{j'}\Bv}
\end{multline*}

There are a couple further manipulations that can be done, since
\(\dotprod{\Ba}{\Bb} = \Ba^T\Bv\), \(\BP^T = \BP^{-1}\), and
\(\BP^{-i} = \BP^{n-i}\).

\begin{multline*}
((n-3)!)^2
\sum_{i=1}^{n-2}\sum_{j=1}^{n-1-i}
\sum_{i'=1}^{n-2}\sum_{j'=1}^{n-1-i'} \\
   \PDPDP{-j}{i'-i}{j'}
  -\PDPDP{-j}{-i-j'}{-i'} \\
  +\PDPDP{i}{j-j'}{-i'}
  -\PDPDP{i}{j+i'}{j'}
\end{multline*}

Well, after all this, I am not actually any closer to getting \(\norm{\crossprod{\Bu}{\Bv}}^2\) evaluated.
Perhaps there is an easier way.  This matrix formulation for \(\crossop{\Bu}\) is a nice way for expression
but it has turned out to be a bit awkward for manipulation, at least without a way to expand \(\PDP{i}{j}\),
which I have not tried for the general case.

\section{Appendix 1}
\subsection{Change of basis, transformations, and rotations}

Given an orthogonal basis \((\ucap_i)_i\) in one coordinate system and an
orthogonal basis \(({\ucap_i}')_i\) for the same coordinate system, how are
the two related?

The two sets of unit vectors can be related by a set of linear equations

\begin{equation}\label{eqn:crossOld:520}
\begin{aligned}
{\ucap_i}' &= \sum_{s=1}^n{a_{is}\ucap_s} \\
\ucap_i &= \sum_{s=1}^n{b_{is}{\ucap_s}'}
\end{aligned}
\end{equation}

What the values of \(a_{ij}\) or \(b_{ij}\) are can be determined by taking inner products and by using the
orthogonality constraints.

\begin{equation}\label{eqn:crossOld:540}
\begin{aligned}
\innerprod{{\ucap_i}'}{\ucap_j} &= \sum_{s=1}^n{a_{is}\innerprod{\ucap_s}{\ucap_j}} \\
                                &= \sum_{s=1}^n{a_{is}\delta_{sj}} \\
                                &= a_{ij} \\
\innerprod{\ucap_i}{{\ucap_j}'} &= \sum_{s=1}^n{b_{is}\innerprod{{\ucap_s}'}{{\ucap_j}'}} \\
                                &= \sum_{s=1}^n{b_{is}\delta_{sj}} \\
                                &= b_{ij} \\
                                &= \overline{a_{ji}} \\
\end{aligned}
\end{equation}

So the relationships between the two sets of basis vectors \({\ucap_i}'\) and \(\ucap_i\) are

\begin{equation}\label{eqn:crossOld:560}
\begin{aligned}
{\ucap_i}'
&= \sum_{s=1}^n{
a_{is}
\ucap_s
}
&=
\sum_{s=1}^n{
\innerprod{{\ucap_i}'}{\ucap_s}
\ucap_s
}
\\
\ucap_i
&= \sum_{s=1}^n{
\overline{a_{si}}
{\ucap_s}'
}
&=
\sum_{s=1}^n{
\innerprod{\ucap_i}{{\ucap_s}'}
{\ucap_s}'
}
\end{aligned}
\end{equation}

Note that these two relationships can be expressed with a transformation
matrix \(\BM\) and its Hermitian transpose \(\BM^*\)

\begin{equation*}
\begin{bmatrix}
{\ucap_1}' \\
{\ucap_2}' \\
\vdots	  \\
{\ucap_n}'
\end{bmatrix}
=
\begin{bmatrix}
	a_{11} & a_{12} & \dots  & a_{1n} \\
        a_{21} & a_{22} & 	  &        \\
	\vdots &        & \ddots &        \\
	a_{n1} & \dots  &        & a_{nn}
\end{bmatrix}
\begin{bmatrix}
\ucap_1  \\
\ucap_2  \\
\vdots	  \\
\ucap_n
\end{bmatrix}
= \BM
\begin{bmatrix}
\ucap_1  \\
\ucap_2  \\
\vdots	  \\
\ucap_n
\end{bmatrix}
\end{equation*}

\begin{equation*}
\begin{bmatrix}
\ucap_1 \\
\ucap_2 \\
\vdots	  \\
\ucap_n
\end{bmatrix}
=
\begin{bmatrix}
	\overline{a_{11}} & \overline{a_{21}} & \dots  & \overline{a_{n1}} \\
        \overline{a_{12}} & \overline{a_{22}} & 	  &        \\
	\vdots &        & \ddots &        \\
	\overline{a_{1n}} & \dots  &        & \overline{a_{nn}}
\end{bmatrix}
\begin{bmatrix}
{\ucap_1}' \\
{\ucap_2}' \\
\vdots	  \\
{\ucap_n}'
\end{bmatrix}
= \BM^*
\begin{bmatrix}
{\ucap_1}' \\
{\ucap_2}' \\
\vdots	  \\
{\ucap_n}'
\end{bmatrix}
\end{equation*}

or

\begin{equation*}
\begin{bmatrix}
{\ucap_1}' \\
{\ucap_2}' \\
\vdots	  \\
{\ucap_n}'
\end{bmatrix}
=
\begin{bmatrix}
	\innerprod{{\ucap_1}'}{\ucap_1} & \innerprod{{\ucap_1}'}{\ucap_2} & \dots  & \innerprod{{\ucap_1}'}{\ucap_n} \\
        \innerprod{{\ucap_2}'}{\ucap_1} & \innerprod{{\ucap_2}'}{\ucap_2} & 	  &        \\
	\vdots &        & \ddots &        \\
	\innerprod{{\ucap_n}'}{\ucap_1} & \dots  &        & \innerprod{{\ucap_n}'}{\ucap_n}
\end{bmatrix}
\begin{bmatrix}
\ucap_1  \\
\ucap_2  \\
\vdots	  \\
\ucap_n
\end{bmatrix}
\end{equation*}

Given an arbitrary vector \(\Br = [r_j]_j\) in the primary coordinate system, one
can express this vector \(\Br' = [r_j']_j\) in the secondary coordinate system using
the same sort procedure used to derive the transformation matrix \(\BM\).

\begin{equation}\label{eqn:crossOld:580}
\begin{aligned}
\Br' &=
      \sum_{s=1}^n
      {
       r_s
       \ucap_s
      } \\
      &=
      \sum_{s=1}^n
      {
       r_s
\sum_{t=1}^n
{
\overline{a_{ts}}
{\ucap_t}'
}
      } \\
      &=
\sum_{t=1}^n
      {
{\ucap_t}'
      \sum_{s=1}^n
{
\overline{a_{ts}}
       r_s
}
      } \\
      &=
\sum_{t=1}^n
      {
{\ucap_t}'
r_t'
      }
\end{aligned}
\end{equation}

Since $r_i' =
      \sum_{s=1}^n
{
\overline{a_{is}}
       r_s
}
$
one can see that the components of the vectors transform
in a similar fashion the
basis vectors, and this can be written \(\Br = \BM^T \Br'\) and \(\Br' = \overline{\BM} \Br\).

When deriving this result seemed odd at first, and found myself wondering if have I messed up despite the fact everything looked okay?  On paper I had only derived this case for \R{n} and not \C{n}.\footnote{
A worked example showed that transformation of the coordinate vectors and the basis vectors do differ by a complex conjugate factor.

Setting \({\ucap_1}' = \inv{\sqrt{2}}(1,i), {\ucap_2}'=\inv{\sqrt{2}}(1,-i)\),
\(\ucap_i = \ecap_i\) the unit vectors in \R{2}, then
$\BM =
\inv{\sqrt{2}}
\Bigl[
\begin{smallmatrix}
1 & i \\
1 & -i
\end{smallmatrix}
\Bigr]
$.  Picking an arbitrary test vector
\(\Br = (1,1) = \ucap_1 + \ucap_2 = \inv{\sqrt{2}}((1-i){\ucap_1}' + (1+i){\ucap_2}')\) the application of the
transformation formulas shows $\Br = \BM^T \Br' =
\inv{\sqrt{2}}
\Bigl[
\begin{smallmatrix}
1 & 1 \\
i & -i
\end{smallmatrix}
\Bigr]
\inv{\sqrt{2}}
\Bigl[
\begin{smallmatrix}
1 - i \\
1 + i
\end{smallmatrix}
\Bigr]
=
\Bigl[
\begin{smallmatrix}
1 \\
1
\end{smallmatrix}
\Bigr]
$ as expected.
}

It does not matter too much, because I do not need the result for the general case in the torque examination anyhow.

%\end{document}               % End of document.
